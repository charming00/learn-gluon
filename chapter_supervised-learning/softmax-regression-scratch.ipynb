{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多类逻辑回归——从零开始\n",
    "\n",
    "如果你读过了[从0开始的线性回归](linear-regression-scratch.md)，那么最难的部分已经过去了。现在你知道如果读取和操作数据，如何构造目标函数和对它求导，如果定义损失函数，模型和求解。\n",
    "\n",
    "下面我们来看一个稍微有意思一点的问题，如何使用多类逻辑回归进行多类分类。这个模型跟线性回归的主要区别在于输出节点从一个变成了多个。\n",
    "\n",
    "![](../img/simple-softmax-net.png)\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "演示这个模型的常见数据集是手写数字识别MNIST，它长这个样子。\n",
    "\n",
    "![](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/example/mnist.png)\n",
    "\n",
    "这里我们用了一个稍微复杂点的数据集，它跟MNIST非常像，但是内容不再是分类数字，而是服饰。我们通过gluon的data.vision模块自动下载这个数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet import image\n",
    "\n",
    "def apply_aug_list(img, augs):\n",
    "    for f in augs:\n",
    "        img = f(img)\n",
    "    return img\n",
    "\n",
    "train_augs = [\n",
    "    image.HorizontalFlipAug(.5)\n",
    "]\n",
    "test_augs = [\n",
    "]\n",
    "\n",
    "def get_transform(augs):\n",
    "    def transform(data, label):\n",
    "        # data: sample x height x width x channel\n",
    "        # label: sample\n",
    "        data = data.astype('float32')/255\n",
    "        if augs is not None:\n",
    "            # apply to each sample one-by-one and then stack\n",
    "            data = nd.stack(*[\n",
    "                apply_aug_list(d, augs) for d in data])\n",
    "        return data, label.astype('float32')\n",
    "    return transform\n",
    "\n",
    "def transform(data, label):\n",
    "    return data.astype('float32')/255, label.astype('float32')\n",
    "mnist_train = gluon.data.vision.MNIST(train=True, transform=get_transform(train_augs))\n",
    "mnist_test = gluon.data.vision.MNIST(train=False, transform=get_transform(test_augs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印一个样本的形状和它的标号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('example shape: ', (28, 28, 1), 'label:', 5.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = mnist_train[0]\n",
    "('example shape: ', data.shape, 'label:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们画出前几个样本的内容，和对应的文本标号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAABkCAYAAACfOkHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb73983f748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images):\n",
    "    n = images.shape[0]\n",
    "    _, figs = plt.subplots(1, n, figsize=(15, 15))\n",
    "    for i in range(n):\n",
    "        figs[i].imshow(images[i].reshape((28, 28)).asnumpy())\n",
    "        figs[i].axes.get_xaxis().set_visible(False)\n",
    "        figs[i].axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "def get_text_labels(label):\n",
    "    text_labels = [\n",
    "        't-shirt', 'trouser', 'pullover', 'dress,', 'coat',\n",
    "        'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'\n",
    "    ]\n",
    "    return [text_labels[int(i)] for i in label]\n",
    "\n",
    "data, label = mnist_train[0:9]\n",
    "show_images(data)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取\n",
    "\n",
    "虽然我们可以像前面那样通过`yield`来定义获取批量数据函数，这里我们直接使用gluon.data的DataLoader函数，它每次`yield`一个批量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_data = gluon.data.DataLoader(mnist_train, batch_size, shuffle=True)\n",
    "test_data = gluon.data.DataLoader(mnist_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到这里我们要求每次从训练数据里读取一个由随机样本组成的批量，但测试数据则不需要这个要求。\n",
    "\n",
    "## 初始化模型参数\n",
    "\n",
    "跟线性模型一样，每个样本会表示成一个向量。我们这里数据是 28 * 28 大小的图片，所以输入向量的长度是 28 * 28 = 784。因为我们要做多类分类，我们需要对每一个类预测这个样本属于此类的概率。因为这个数据集有10个类型，所以输出应该是长为10的向量。这样，我们需要的权重将是一个 784 * 10 的矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "W = nd.random_normal(shape=(num_inputs, num_outputs))\n",
    "b = nd.random_normal(shape=num_outputs)\n",
    "\n",
    "params = [W, b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同之前一样，我们要对模型参数附上梯度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "\n",
    "在线性回归教程里，我们只需要输出一个标量`yhat`使得尽可能的靠近目标值。但在这里的分类里，我们需要属于每个类别的概率。这些概率需要值为正，而且加起来等于1. 而如果简单的使用 $\\boldsymbol{\\hat y} = \\boldsymbol{W} \\boldsymbol{x}$, 我们不能保证这一点。一个通常的做法是通过softmax函数来将任意的输入归一化成合法的概率值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "def softmax(X):\n",
    "    exp = nd.exp(X)\n",
    "    # 假设exp是矩阵，这里对行进行求和，并要求保留axis 1，\n",
    "    # 就是返回 (nrows, 1) 形状的矩阵\n",
    "    partition = exp.sum(axis=1, keepdims=True)\n",
    "    return exp / partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，对于随机输入，我们将每个元素变成了非负数，而且每一行加起来为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.07024596  0.38768554  0.06740031  0.21249865  0.26216954]\n",
      " [ 0.06539094  0.1500023   0.36792335  0.02470051  0.39198291]]\n",
      "<NDArray 2x5 @cpu(0)>\n",
      "\n",
      "[ 1.  1.]\n",
      "<NDArray 2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "X = nd.random_normal(shape=(2,5))\n",
    "X_prob = softmax(X)\n",
    "print(X_prob)\n",
    "print(X_prob.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以定义模型了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(nd.dot(X.reshape((-1,num_inputs)), W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉熵损失函数\n",
    "\n",
    "我们需要定义一个针对预测为概率值的损失函数。其中最常见的是交叉熵损失函数，它将两个概率分布的负交叉熵作为目标值，最小化这个值等价于最大化这两个概率的相似度。\n",
    "\n",
    "具体来说，我们先将真实标号表示成一个概率分布，例如如果`y=1`，那么其对应的分布就是一个除了第二个元素为1其他全为0的长为10的向量，也就是 `yvec=[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]`。那么交叉熵就是`yvec[0]*log(yhat[0])+...+yvec[n]*log(yhat[n])`。注意到`yvec`里面只有一个1，那么前面等价于`log(yhat[y])`。所以我们可以定义这个损失函数了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(yhat, y):\n",
    "    return - nd.pick(nd.log(yhat), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算精度\n",
    "\n",
    "给定一个概率输出，我们将预测概率最高的那个类作为预测的类，然后通过比较真实标号我们可以计算精度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(output, label):\n",
    "    return nd.mean(output.argmax(axis=1)==label).asscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以评估一个模型在这个数据上的精度。（这两个函数我们之后也会用到，所以也都保存在[../utils.py](../utils.py)。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = 0.\n",
    "    for data, label in data_iterator:\n",
    "        output = net(data)\n",
    "        acc += accuracy(output, label)\n",
    "    return acc / len(data_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我们随机初始化了模型，所以这个模型的精度应该大概是`1/num_outputs = 0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11845703125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(test_data, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "训练代码跟前面的线性回归非常相似："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 4.300033, Train acc 0.425139, Test acc 0.632812\n",
      "Epoch 1. Loss: 1.685699, Train acc 0.680131, Test acc 0.738184\n",
      "Epoch 2. Loss: 1.254052, Train acc 0.748720, Test acc 0.778125\n",
      "Epoch 3. Loss: 1.062114, Train acc 0.782402, Test acc 0.800684\n",
      "Epoch 4. Loss: 0.949444, Train acc 0.801917, Test acc 0.817578\n",
      "Epoch 5. Loss: 0.871440, Train acc 0.815071, Test acc 0.829199\n",
      "Epoch 6. Loss: 0.813980, Train acc 0.824701, Test acc 0.837598\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4ed197b8a687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             generator = lambda: [(yield self._batchify_fn([self._dataset[idx] for idx in batch]))\n\u001b[0;32m--> 279\u001b[0;31m                                  for batch in self._batch_sampler]\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             generator = lambda: [(yield self._batchify_fn([self._dataset[idx] for idx in batch]))\n\u001b[0m\u001b[1;32m    279\u001b[0m                                  for batch in self._batch_sampler]\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-0d520727ea12>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(data, label)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# apply to each sample one-by-one and then stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             data = nd.stack(*[\n\u001b[0;32m---> 24\u001b[0;31m                 apply_aug_list(d, augs) for d in data])\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-0d520727ea12>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# apply to each sample one-by-one and then stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             data = nd.stack(*[\n\u001b[0;32m---> 24\u001b[0;31m                 apply_aug_list(d, augs) for d in data])\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-0d520727ea12>\u001b[0m in \u001b[0;36mapply_aug_list\u001b[0;34m(img, augs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_aug_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maugs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/image/image.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;34m\"\"\"Augmenter body\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m(data, axis, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         ctypes.byref(out_stypes)))\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         ctypes.byref(out_stypes)))\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import SGD\n",
    "from mxnet import autograd\n",
    "\n",
    "learning_rate = .1\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for data, label in train_data:\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        # 将梯度做平均，这样学习率会对batch size不那么敏感\n",
    "        SGD(params, learning_rate/batch_size)\n",
    "\n",
    "        train_loss += nd.mean(loss).asscalar()\n",
    "        train_acc += accuracy(output, label)\n",
    "\n",
    "    test_acc = evaluate_accuracy(test_data, net)\n",
    "    print(\"Epoch %d. Loss: %f, Train acc %f, Test acc %f\" % (\n",
    "        epoch, train_loss/len(train_data), train_acc/len(train_data), test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测\n",
    "\n",
    "训练完成后，现在我们可以演示对输入图片的标号的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    }
   },
   "outputs": [],
   "source": [
    "data, label = mnist_test[40:49]\n",
    "show_images(data)\n",
    "print('true labels')\n",
    "print(label)\n",
    "\n",
    "predicted_labels = net(data).argmax(axis=1)\n",
    "print('predicted labels')\n",
    "print((predicted_labels.asnumpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结论\n",
    "\n",
    "与前面的线性回归相比，你会发现多类逻辑回归教程的结构跟其非常相似：获取数据、定义模型及优化算法和求解。事实上，几乎所有的实际神经网络应用都有着同样结构。他们的主要区别在于模型的类型和数据的规模。每一两年会有一个新的优化算法出来，但它们基本都是随机梯度下降的变种。\n",
    "\n",
    "## 练习\n",
    "\n",
    "尝试增大学习率，你会马上发现结果变得很糟糕，精度基本徘徊在随机的0.1左右。这是为什么呢？提示：\n",
    "\n",
    "- 打印下output看看是不是有什么异常\n",
    "- 前面线性回归还好好的，这里我们在net()里加了什么呢？\n",
    "- 如果给exp输入个很大的数会怎么样？\n",
    "- 即使解决exp的问题，求出来的导数是不是还是不稳定？\n",
    "\n",
    "请仔细想想再去对比下我们小伙伴之一@[pluskid](https://github.com/pluskid)早年写的一篇[blog解释这个问题](http://freemind.pluskid.org/machine-learning/softmax-vs-softmax-loss-numerical-stability/)，看看你想的是不是不一样。\n",
    "\n",
    "**吐槽和讨论欢迎点**[这里](https://discuss.gluon.ai/t/topic/741)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
