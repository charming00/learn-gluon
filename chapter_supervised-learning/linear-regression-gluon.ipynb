{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归——使用Gluon\n",
    "\n",
    "[前一章](linear-regression-scratch.md)我们仅仅使用了`ndarray`和`autograd`来实现线性回归，这一章我们仍然实现同样的模型，但是使用高层抽象包`gluon`。\n",
    "\n",
    "## 创建数据集\n",
    "\n",
    "我们生成同样的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[[-0.41213271  1.52278841]\n",
      "  [ 1.24897444 -0.33277884]\n",
      "  [-0.48362762 -0.92140299]]\n",
      "\n",
      " [[ 0.25383762 -0.03598363]\n",
      "  [-0.11660124 -0.2931439 ]\n",
      "  [ 1.48245633 -0.58981359]]\n",
      "\n",
      " [[ 0.81097436 -0.52307099]\n",
      "  [ 1.12914741  0.03926884]\n",
      "  [ 0.16556863 -0.97811055]]\n",
      "\n",
      " ..., \n",
      " [[-0.11661945  2.1543231 ]\n",
      "  [-1.02014947  1.11945248]\n",
      "  [-1.32146716  0.7630707 ]]\n",
      "\n",
      " [[ 1.38129365  2.0401516 ]\n",
      "  [ 0.47268888 -0.54245782]\n",
      "  [-0.37366498  0.15885045]]\n",
      "\n",
      " [[-1.82788789  1.38307118]\n",
      "  [-0.65179902 -0.29327434]\n",
      "  [-0.38820505 -0.48204207]]]\n",
      "<NDArray 1000x3x2 @cpu(0)>\n",
      "\n",
      "[[ -0.8619889    8.38162613]\n",
      " [  5.0962925    5.11252403]\n",
      " [  1.98307872   3.02418923]\n",
      " ..., \n",
      " [  7.42876911   4.70107698]\n",
      " [  5.33990431  10.12491703]\n",
      " [  2.77331471   7.97042847]]\n",
      "<NDArray 1000x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "from mxnet import ndarray as nd\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "\n",
    "data_root = '../data'\n",
    "txt_root = data_root + '/CephalometricLandmark/AnnotationsByMD'\n",
    "for i in range(150):\n",
    "    txt_filename1 = txt_root + '/400_senior' + \"/%03d.txt\" % i\n",
    "    with open(txt_filename1, 'r') as f:\n",
    "        txts = f.read().split()\n",
    "\n",
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "X = nd.random_normal(shape=(num_examples, num_inputs))\n",
    "y = true_w[0] * X[:, 0] + true_w[1] * X[:, 1] + true_b\n",
    "y += .01 * nd.random_normal(shape=y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取\n",
    "\n",
    "但这里使用`data`模块来读取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "dataset = gluon.data.ArrayDataset(X, y)\n",
    "data_iter = gluon.data.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取跟前面一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 1.0630331   0.17892691]\n",
      " [-1.86081767  1.38656259]\n",
      " [ 2.58488894 -1.14167035]\n",
      " [ 0.5074473   0.07947154]\n",
      " [-1.7132839   0.08990741]\n",
      " [-1.07668817 -0.75819719]\n",
      " [-0.6686148   1.38497305]\n",
      " [-0.29596215  1.83803487]\n",
      " [-1.35992277  0.57972157]\n",
      " [ 0.09210896 -0.1585041 ]]\n",
      "<NDArray 10x2 @cpu(0)> \n",
      "[  5.72280836  -4.23733759  13.25807858   4.94102526   0.46718451\n",
      "   4.63486099  -1.83509505  -2.64578891  -0.48840913   4.92344046]\n",
      "<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for data, label in data_iter:\n",
    "    print(data, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "\n",
    "之前一章中，当我们从0开始训练模型时，需要先声明模型参数，然后再使用它们来构建模型。但`gluon`提供大量预定义的层，我们只需要关注使用哪些层来构建模型。例如线性模型就是使用对应的`Dense`层；之所以称为dense层，是因为输入的所有节点都与后续的节点相连。在这个例子中仅有一个输出，但在大多数后续章节中，我们会用到具有多个输出的网络。\n",
    "\n",
    "我们之后还会介绍如何构造任意结构的神经网络，但对于初学者来说，构建模型最简单的办法是利用`Sequential`来所有层串起来。输入数据之后，`Sequential`会依次执行每一层，并将前一层的输出，作为输入提供给后面的层。首先我们定义一个空的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = gluon.nn.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们加入一个`Dense`层，它唯一必须定义的参数就是输出节点的个数，在线性模型里面是1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.add(gluon.nn.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（注意这里我们并没有定义说这个层的输入节点是多少，这个在之后真正给数据的时候系统会自动赋值。我们之后会详细介绍这个特性是如何工作的。）\n",
    "\n",
    "## 初始化模型参数\n",
    "\n",
    "在使用前`net`我们必须要初始化模型权重，这里我们使用默认随机初始化方法（之后我们会介绍更多的初始化方法）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "\n",
    "`gluon`提供了平方误差函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "square_loss = gluon.loss.L2Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化\n",
    "\n",
    "同样我们无需手动实现随机梯度下降，我们可以创建一个`Trainer`的实例，并且将模型参数传递给它就行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(\n",
    "    net.collect_params(), 'sgd', {'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "使用`gluon`使模型训练过程更为简洁。我们不需要挨个定义相关参数、损失函数，也不需使用随机梯度下降。`gluon`的抽象和便利的优势将随着我们着手处理更多复杂模型的愈发显现。不过在完成初始设置后，训练过程本身和前面没有太多区别，唯一的不同在于我们不再是调用`SGD`，而是`trainer.step`来更新模型（此处一并省略之前绘制损失变化的折线图和散点图的过程，有兴趣的同学可以自行尝试）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss: 0.909584\n",
      "Epoch 1, average loss: 0.000051\n",
      "Epoch 2, average loss: 0.000051\n",
      "Epoch 3, average loss: 0.000051\n",
      "Epoch 4, average loss: 0.000051\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 10\n",
    "for e in range(epochs):\n",
    "    total_loss = 0\n",
    "    for data, label in data_iter:\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = square_loss(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "        total_loss += nd.sum(loss).asscalar()\n",
    "    print(\"Epoch %d, average loss: %f\" % (e, total_loss/num_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较学到的和真实模型。我们先从`net`拿到需要的层，然后访问其权重和位移。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, -3.4], \n",
       " [[ 2.00104523 -3.3992312 ]]\n",
       " <NDArray 1x2 @cpu(0)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = net[0]\n",
    "true_w, dense.weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.2, \n",
       " [ 4.20073891]\n",
       " <NDArray 1 @cpu(0)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_b, dense.bias.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结论\n",
    "\n",
    "可以看到`gluon`可以帮助我们更快更干净地实现模型。\n",
    "\n",
    "\n",
    "## 练习\n",
    "\n",
    "- 在训练的时候，为什么我们用了比前面要大10倍的学习率呢？（提示：可以尝试运行 `help(trainer.step)`来寻找答案。）\n",
    "- 如何拿到`weight`的梯度呢？（提示：尝试 `help(dense.weight)`）\n",
    "\n",
    "**吐槽和讨论欢迎点**[这里](https://discuss.gluon.ai/t/topic/742)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
