{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mxnet import nd\n",
    "from mxnet import image\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from time import time\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "from mxnet import init\n",
    "import random\n",
    "import mxnet as mx\n",
    "import math\n",
    "\n",
    "classes = ['background', 'p1', 'p2', 'p3', 'p4',\n",
    "           'p5', 'p6', 'p7', 'p8', 'p9', 'p10',\n",
    "           'p11', 'p12', 'p13', 'p14', 'p15',\n",
    "           'p16', 'p17', 'p18', 'p19']\n",
    "colormap = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128],\n",
    "            [128, 0, 128], [0, 64, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0],\n",
    "            [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128],\n",
    "            [64, 128, 128], [192, 128, 128], [0, 64, 0], [128, 64, 0],\n",
    "            [0, 192, 0], [128, 192, 0]]\n",
    "min_coordinate = [[504, 697], [1063, 606], [948, 888], [286, 902], [1079, 1191], [1053, 1507], [1048, 1661],\n",
    "                  [993, 1729], [1025, 1706], [415, 1391], [1121, 1355], [1138, 1388], [1245, 1294],\n",
    "                  [1212, 1477], [1170, 1152], [1114, 1756], [635, 1090], [1081, 1100], [350, 1006]]\n",
    "expand_size = 320\n",
    "landmark_index = 2\n",
    "data_root = '../data'\n",
    "image_root = data_root + '/CephalometricLandmark/Net0Image'\n",
    "txt_root = data_root + '/CephalometricLandmark/AnnotationsByMD'\n",
    "model_params_root = data_root + '/CephalometricLandmark/model_params'\n",
    "rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "learning_rate = 0.1\n",
    "\n",
    "for all_round_index in range(100):\n",
    "    #     image_root = data_root + '/CephalometricLandmark/ContrastImage1'\n",
    "    #     for expand_size in range(80, 160, 5):\n",
    "    for landmark_index in range(0, 19):\n",
    "        #     for landmark_index in [2,3,5,9,12,15]:\n",
    "        learning_rate = 0.1\n",
    "\n",
    "\n",
    "        def read_images(dataset_num=0):\n",
    "\n",
    "            if dataset_num == 0:\n",
    "                begin_index = 1\n",
    "                end_index = 151\n",
    "            elif dataset_num == 1:\n",
    "                begin_index = 151\n",
    "                end_index = 301\n",
    "            else:\n",
    "                begin_index = 301\n",
    "                end_index = 401\n",
    "\n",
    "            data, label = [None] * (end_index - begin_index), [None] * (end_index - begin_index)\n",
    "            index = 0\n",
    "            for i in range(begin_index, end_index):\n",
    "                image_filename = image_root + \"/%03d.bmp\" % (i)\n",
    "                txt_filename2 = txt_root + '/400_junior' + \"/%03d.txt\" % i\n",
    "                # #         label_image[index] = nd.zeros_like(data[index])\n",
    "\n",
    "                with open(txt_filename2, 'r') as f:\n",
    "                    txts1 = f.read().split()\n",
    "                x = int(txts1[landmark_index].split(',')[0]) - 335\n",
    "                y = int(txts1[landmark_index].split(',')[1]) - 480\n",
    "                #         label_image[index][y-expand_size:y+expand_size,x-expand_size:x+expand_size] = colormap[landmark_index+1]\n",
    "                #             x = int(txts1[landmark_index].split(',')[0])- min_coordinate[landmark_index][0]\n",
    "                #             y = int(txts1[landmark_index].split(',')[1])- min_coordinate[landmark_index][1]\n",
    "                minx = x - expand_size\n",
    "                maxx = x + expand_size\n",
    "                if minx < 0:\n",
    "                    minx = 0\n",
    "                if maxx >= 1600:\n",
    "                    maxx = 1600 - 1\n",
    "\n",
    "                miny = y - expand_size\n",
    "                maxy = y + expand_size\n",
    "                if miny < 0:\n",
    "                    miny = 0\n",
    "                if maxy >= 1920:\n",
    "                    maxy = 1920 - 1\n",
    "                data[index] = image.imread(image_filename)\n",
    "                label[index] = nd.zeros((data[index].shape[0], data[index].shape[1]))\n",
    "                label[index][miny:maxy, minx:maxx] = 1\n",
    "                #             label[index] = nd.flip(label[index],0)\n",
    "                #             print(data[index].shape,label[index].shape)\n",
    "                index += 1\n",
    "            return data, label\n",
    "\n",
    "\n",
    "        def normalize_image(data):\n",
    "            #             noise = nd.zeros((640, 640, 1))\n",
    "            #             if random.random() > 0.2:\n",
    "            #                 mx.random.seed(np.random.randint(1, 1000))\n",
    "            #                 noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "            #             return ((data.astype('float32')+ 10*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "            return (data.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "\n",
    "\n",
    "        class VOCSegDataset(gluon.data.Dataset):\n",
    "\n",
    "            def __init__(self, dataset_num, crop_size):\n",
    "                self.crop_size = crop_size\n",
    "                self.data, self.label = read_images(dataset_num=dataset_num)\n",
    "                self.data[:] = [normalize_image(im) for im in self.data]\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                data = self.data[idx]\n",
    "                label = self.label[idx]\n",
    "\n",
    "                #                 aug1 = image.HorizontalFlipAug(1)\n",
    "                #                 aug2 = image.BrightnessJitterAug(1)\n",
    "                #                 aug3 = image.ContrastJitterAug(1)\n",
    "                #                 if random.random() > 0.5:\n",
    "                #                     data = aug1(data)\n",
    "                #                     label = nd.flip(label,1)\n",
    "                #                 data = aug2(data)\n",
    "                return data.transpose((2, 0, 1)), label\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.data)\n",
    "\n",
    "\n",
    "        input_shape = (1600, 1920)\n",
    "        voc_train = VOCSegDataset(0, input_shape)\n",
    "        voc_test1 = VOCSegDataset(1, input_shape)\n",
    "\n",
    "        batch_size = 4\n",
    "        train_data = gluon.data.DataLoader(\n",
    "            voc_train, batch_size, shuffle=True, last_batch='discard')\n",
    "        test_data = gluon.data.DataLoader(\n",
    "            voc_test1, batch_size, last_batch='discard')\n",
    "\n",
    "        conv = nn.Conv2D(10, kernel_size=4, padding=1, strides=2)\n",
    "        conv_trans = nn.Conv2DTranspose(3, kernel_size=4, padding=1, strides=2)\n",
    "\n",
    "        conv.initialize()\n",
    "        conv_trans.initialize()\n",
    "\n",
    "        pretrained_net = models.resnet18_v2(pretrained=True)\n",
    "\n",
    "        net = nn.HybridSequential()\n",
    "        for layer in pretrained_net.features[:-2]:\n",
    "            net.add(layer)\n",
    "\n",
    "        num_classes = len(classes)\n",
    "\n",
    "        with net.name_scope():\n",
    "            net.add(\n",
    "                nn.Conv2D(2, kernel_size=1),\n",
    "                nn.Conv2DTranspose(2, kernel_size=64, padding=16, strides=32)\n",
    "            )\n",
    "\n",
    "\n",
    "        def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "            factor = (kernel_size + 1) // 2\n",
    "            if kernel_size % 2 == 1:\n",
    "                center = factor - 1\n",
    "            else:\n",
    "                center = factor - 0.5\n",
    "            og = np.ogrid[:kernel_size, :kernel_size]\n",
    "            filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "                   (1 - abs(og[1] - center) / factor)\n",
    "            weight = np.zeros(\n",
    "                (in_channels, out_channels, kernel_size, kernel_size),\n",
    "                dtype='float32')\n",
    "            weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "            return nd.array(weight)\n",
    "\n",
    "\n",
    "        conv_trans = net[-1]\n",
    "        conv_trans.initialize(init=init.Zero())\n",
    "        net[-2].initialize(init=init.Xavier())\n",
    "\n",
    "        x = nd.zeros((batch_size, 3, *input_shape))\n",
    "        net(x)\n",
    "        model_path = model_params_root + \"/net0-mark%02d-resnet18-epochs100.json\" % (landmark_index + 1)\n",
    "        net.save_params(model_path)\n",
    "        shape = conv_trans.weight.data().shape\n",
    "        conv_trans.weight.set_data(bilinear_kernel(*shape[0:3]))\n",
    "\n",
    "        loss = gluon.loss.SoftmaxCrossEntropyLoss(axis=1)\n",
    "\n",
    "        ctx = utils.try_all_gpus()\n",
    "        net.collect_params().reset_ctx(ctx)\n",
    "        trainer = gluon.Trainer(net.collect_params(),\n",
    "                                'sgd', {'learning_rate': learning_rate, 'wd': 1e-3})\n",
    "\n",
    "        utils.train(train_data, test_data, net, loss,\n",
    "                    trainer, ctx, num_epochs=10)\n",
    "        print(\"landmark \", str(landmark_index), \"save !\")\n",
    "        model_path = model_params_root + \"/net0-mark%02d-resnet18-epochs100.json\" % (landmark_index + 1)\n",
    "        net.save_params(model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
