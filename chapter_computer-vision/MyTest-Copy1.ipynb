{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index :  2  round :  10  test1 acc :  0.633 0.673 0.700 0.767 0.773 0.847 0.860 0.947\n",
      "index :  2  round :  10  test2 acc :  0.610 0.600 0.700 0.710 0.800 0.830 0.890 0.920\n",
      "index :  2  round :  20  test1 acc :  0.653 0.693 0.793 0.827 0.833 0.887 0.900 0.940\n",
      "index :  2  round :  20  test2 acc :  0.590 0.610 0.720 0.770 0.800 0.840 0.880 0.940\n",
      "index :  2  round :  30  test1 acc :  0.660 0.687 0.760 0.787 0.840 0.867 0.927 0.947\n",
      "index :  2  round :  30  test2 acc :  0.610 0.620 0.740 0.770 0.820 0.880 0.900 0.960\n",
      "index :  2  round :  40  test1 acc :  0.653 0.693 0.793 0.813 0.853 0.880 0.927 0.947\n",
      "index :  2  round :  40  test2 acc :  0.590 0.600 0.750 0.790 0.830 0.860 0.900 0.950\n",
      "index :  2  round :  50  test1 acc :  0.653 0.700 0.773 0.800 0.847 0.880 0.920 0.947\n",
      "index :  2  round :  50  test2 acc :  0.610 0.620 0.700 0.780 0.820 0.870 0.900 0.940\n",
      "\n",
      "index :  3  round :  10  test1 acc :  0.447 0.453 0.567 0.613 0.700 0.680 0.813 0.800\n",
      "index :  3  round :  10  test2 acc :  0.530 0.550 0.610 0.620 0.670 0.670 0.760 0.760\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mxnet import nd\n",
    "from mxnet import image\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from time import time\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "from mxnet import init\n",
    "import random\n",
    "import mxnet as mx\n",
    "import math\n",
    "\n",
    "classes = ['background', 'p1', 'p2', 'p3', 'p4',\n",
    "           'p5', 'p6', 'p7', 'p8', 'p9', 'p10',\n",
    "           'p11', 'p12', 'p13', 'p14', 'p15',\n",
    "           'p16', 'p17', 'p18', 'p19']\n",
    "colormap = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128],\n",
    "            [128, 0, 128], [0, 64, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0],\n",
    "            [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128],\n",
    "            [64, 128, 128], [192, 128, 128], [0, 64, 0], [128, 64, 0],\n",
    "            [0, 192, 0], [128, 192, 0]]\n",
    "min_coordinate = [[504, 697], [1063, 606], [948, 888], [286, 902], [1079, 1191], [1053, 1507], [1048, 1661],\n",
    "                  [993, 1729], [1025, 1706], [415, 1391], [1121, 1355], [1138, 1388], [1245, 1294],\n",
    "                  [1212, 1477], [1170, 1152], [1114, 1756], [635, 1090], [1081, 1100], [350, 1006]]\n",
    "expand_size = 55\n",
    "landmark_index = 2\n",
    "data_root = '../data'\n",
    "image_root = data_root + '/CephalometricLandmark/CroppedImage'\n",
    "txt_root = data_root + '/CephalometricLandmark/AnnotationsByMD'\n",
    "rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "learning_rate = 0.01\n",
    "\n",
    "for round_index in range(100):\n",
    "    #     image_root = data_root + '/CephalometricLandmark/ContrastImage1'\n",
    "    #     for expand_size in range(80, 160, 5):\n",
    "#     for landmark_index in range(2, 5):\n",
    "    for landmark_index in [2,3,5,9,12,15]:\n",
    "        learning_rate = 0.01\n",
    "        print()\n",
    "\n",
    "\n",
    "        def read_images(dataset_num=0):\n",
    "\n",
    "            if dataset_num == 0:\n",
    "                begin_index = 1\n",
    "                end_index = 151\n",
    "            elif dataset_num == 1:\n",
    "                begin_index = 151\n",
    "                end_index = 301\n",
    "            else:\n",
    "                begin_index = 301\n",
    "                end_index = 401\n",
    "\n",
    "            data, label = [None] * (end_index - begin_index), [None] * (end_index - begin_index)\n",
    "            index = 0\n",
    "            for i in range(begin_index, end_index):\n",
    "                image_filename = image_root + \"/%02d/%03d.bmp\" % (landmark_index + 1, i)\n",
    "                txt_filename1 = txt_root + '/400_senior' + \"/%03d.txt\" % i\n",
    "                txt_filename2 = txt_root + '/400_junior' + \"/%03d.txt\" % i\n",
    "                # #         label_image[index] = nd.zeros_like(data[index])\n",
    "\n",
    "#                 with open(txt_filename1, 'r') as f:\n",
    "#                     txts1 = f.read().split()\n",
    "                with open(txt_filename2, 'r') as f:\n",
    "                    txts2 = f.read().split()\n",
    "#                 x = int((int(txts1[landmark_index].split(',')[0]) + int(txts2[landmark_index].split(',')[0])) / 2) - \\\n",
    "#                     min_coordinate[landmark_index][0]\n",
    "#                 y = int((int(txts1[landmark_index].split(',')[1]) + int(txts2[landmark_index].split(',')[1])) / 2) - \\\n",
    "#                     min_coordinate[landmark_index][1]\n",
    "                x = int(txts2[landmark_index].split(',')[0]) - min_coordinate[landmark_index][0]\n",
    "                y = int(txts2[landmark_index].split(',')[1]) - min_coordinate[landmark_index][1]\n",
    "                minx = x - expand_size\n",
    "                maxx = x + expand_size\n",
    "                if minx < 0:\n",
    "                    minx = 0\n",
    "                if maxx >= 640:\n",
    "                    maxx = 639\n",
    "\n",
    "                miny = y - expand_size\n",
    "                maxy = y + expand_size\n",
    "                if miny < 0:\n",
    "                    miny = 0\n",
    "                if maxy >= 640:\n",
    "                    maxy = 639\n",
    "\n",
    "                data[index] = image.imread(image_filename)\n",
    "                label[index] = nd.zeros((data[index].shape[0], data[index].shape[1]))\n",
    "                label[index][miny:maxy, minx:maxx] = 1\n",
    "                index += 1\n",
    "            return data, label\n",
    "\n",
    "\n",
    "        def normalize_image(data):\n",
    "            #             noise = nd.zeros((640, 640, 1))\n",
    "            #             if random.random() > 0.2:\n",
    "            #                 mx.random.seed(np.random.randint(1, 1000))\n",
    "            #                 noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "            #             return ((data.astype('float32')+ 10*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "            return (data.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "\n",
    "\n",
    "        class VOCSegDataset(gluon.data.Dataset):\n",
    "\n",
    "            def __init__(self, dataset_num, crop_size):\n",
    "                self.crop_size = crop_size\n",
    "                self.data, self.label = read_images(dataset_num=dataset_num)\n",
    "                self.data[:] = [normalize_image(im) for im in self.data]\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                data = self.data[idx]\n",
    "                label = self.label[idx]\n",
    "\n",
    "                #                 aug1 = image.HorizontalFlipAug(1)\n",
    "                #                 aug2 = image.BrightnessJitterAug(1)\n",
    "                #                 aug3 = image.ContrastJitterAug(1)\n",
    "                #                 if random.random() > 0.5:\n",
    "                #                     data = aug1(data)\n",
    "                #                     label = nd.flip(label,1)\n",
    "                #                 data = aug2(data)\n",
    "                return data.transpose((2, 0, 1)), label\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.data)\n",
    "\n",
    "\n",
    "        input_shape = (640, 640)\n",
    "        voc_train = VOCSegDataset(0, input_shape)\n",
    "        voc_test1 = VOCSegDataset(1, input_shape)\n",
    "\n",
    "        batch_size = 4\n",
    "        train_data = gluon.data.DataLoader(\n",
    "            voc_train, batch_size, shuffle=True, last_batch='discard')\n",
    "        test_data = gluon.data.DataLoader(\n",
    "            voc_test1, batch_size, last_batch='discard')\n",
    "\n",
    "        conv = nn.Conv2D(10, kernel_size=4, padding=1, strides=2)\n",
    "        conv_trans = nn.Conv2DTranspose(3, kernel_size=4, padding=1, strides=2)\n",
    "\n",
    "        conv.initialize()\n",
    "        conv_trans.initialize()\n",
    "\n",
    "        pretrained_net = models.resnet50_v2(pretrained=True)\n",
    "\n",
    "        net = nn.HybridSequential()\n",
    "        for layer in pretrained_net.features[:-2]:\n",
    "            net.add(layer)\n",
    "\n",
    "        num_classes = len(classes)\n",
    "\n",
    "        with net.name_scope():\n",
    "            net.add(\n",
    "                nn.Conv2D(2, kernel_size=1),\n",
    "                nn.Conv2DTranspose(2, kernel_size=64, padding=16, strides=32)\n",
    "            )\n",
    "\n",
    "\n",
    "        def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "            factor = (kernel_size + 1) // 2\n",
    "            if kernel_size % 2 == 1:\n",
    "                center = factor - 1\n",
    "            else:\n",
    "                center = factor - 0.5\n",
    "            og = np.ogrid[:kernel_size, :kernel_size]\n",
    "            filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "                   (1 - abs(og[1] - center) / factor)\n",
    "            weight = np.zeros(\n",
    "                (in_channels, out_channels, kernel_size, kernel_size),\n",
    "                dtype='float32')\n",
    "            weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "            return nd.array(weight)\n",
    "\n",
    "\n",
    "        conv_trans = net[-1]\n",
    "        conv_trans.initialize(init=init.Zero())\n",
    "        net[-2].initialize(init=init.Xavier())\n",
    "\n",
    "        x = nd.zeros((batch_size, 3, *input_shape))\n",
    "        net(x)\n",
    "\n",
    "        shape = conv_trans.weight.data().shape\n",
    "        conv_trans.weight.set_data(bilinear_kernel(*shape[0:3]))\n",
    "\n",
    "        for round_num in range(5):\n",
    "\n",
    "            loss = gluon.loss.SoftmaxCrossEntropyLoss(axis=1)\n",
    "\n",
    "            ctx = utils.try_all_gpus()\n",
    "            net.collect_params().reset_ctx(ctx)\n",
    "            trainer = gluon.Trainer(net.collect_params(),\n",
    "                                    'NAG', {'learning_rate': learning_rate, 'wd': 1e-3})\n",
    "\n",
    "            utils.train(train_data, test_data, net, loss,\n",
    "                        trainer, ctx, num_epochs=10)\n",
    "            \n",
    "            learning_rate = learning_rate / 2\n",
    "            \n",
    "\n",
    "            def predict(im):\n",
    "                data = normalize_image(im)\n",
    "                #                 data = (im.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "                data = data.transpose((2, 0, 1)).expand_dims(axis=0)\n",
    "                yhat = net(data.as_in_context(ctx[0]))\n",
    "                pred = nd.argmax(yhat, axis=1)\n",
    "                return pred.reshape((pred.shape[1], pred.shape[2]))\n",
    "\n",
    "\n",
    "            def label2image(pred):\n",
    "                x = pred.astype('int32').asnumpy()\n",
    "                cm = nd.array(colormap).astype('uint8')\n",
    "                return nd.array(cm[x, :])\n",
    "\n",
    "\n",
    "            def evaluate_acc(result, label):\n",
    "                if (len(np.where(result.asnumpy() > 0)[1]) == 0):\n",
    "                    return False, False, False, False, False, False, False, False\n",
    "                result_maxx = np.max(np.where(result.asnumpy() > 0)[1])\n",
    "                result_minx = np.min(np.where(result.asnumpy() > 0)[1])\n",
    "                result_maxy = np.max(np.where(result.asnumpy() > 0)[0])\n",
    "                result_miny = np.min(np.where(result.asnumpy() > 0)[0])\n",
    "\n",
    "                result_centerx = int((result_maxx + result_minx) / 2)\n",
    "                result_centery = int((result_maxy + result_miny) / 2)\n",
    "\n",
    "                result_avgx = np.average(np.where(result.asnumpy() > 0)[1])\n",
    "                result_avgy = np.average(np.where(result.asnumpy() > 0)[0])\n",
    "\n",
    "                label_maxx = np.max(np.where(label.asnumpy() > 0)[1])\n",
    "                label_minx = np.min(np.where(label.asnumpy() > 0)[1])\n",
    "                label_maxy = np.max(np.where(label.asnumpy() > 0)[0])\n",
    "                label_miny = np.min(np.where(label.asnumpy() > 0)[0])\n",
    "\n",
    "                label_centerx = int((label_maxx + label_minx) / 2)\n",
    "                label_centery = int((label_maxy + label_miny) / 2)\n",
    "\n",
    "                d1 = pow((result_centerx - label_centerx), 2) + pow((result_centery - label_centery), 2)\n",
    "                d2 = pow((result_avgx - label_centerx), 2) + pow((result_avgy - label_centery), 2)\n",
    "                #     print(\"============================\")\n",
    "                #     print(np.where(result.asnumpy()>0))\n",
    "#                 print(result_centerx,label_centerx,result_centery,label_centery,math.sqrt(d1),math.sqrt(d2))\n",
    "                return (d1 < 400, d2 < 400, d1 < 625, d2 < 625, d1 < 900, d2 < 900, d1 < 1600, d2 < 1600)\n",
    "\n",
    "\n",
    "            test_images, test_labels = read_images(1)\n",
    "            n = len(test_images)\n",
    "            acc1 = 0\n",
    "            acc2 = 0\n",
    "            acc3 = 0\n",
    "            acc4 = 0\n",
    "            acc5 = 0\n",
    "            acc6 = 0\n",
    "            acc7 = 0\n",
    "            acc8 = 0\n",
    "            # print(test_images[0])\n",
    "            for i in range(n):\n",
    "                x = test_images[i]\n",
    "#                 print(i+1)\n",
    "                #     print(x.shape)\n",
    "                #     start = time()\n",
    "                result = predict(x)\n",
    "                f1, f2, f3, f4, f5, f6, f7, f8 = evaluate_acc(result, test_labels[i])\n",
    "                acc1 += int(f1)\n",
    "                acc2 += int(f2)\n",
    "                acc3 += int(f3)\n",
    "                acc4 += int(f4)\n",
    "                acc5 += int(f5)\n",
    "                acc6 += int(f6)\n",
    "                acc7 += int(f7)\n",
    "                acc8 += int(f8)\n",
    "\n",
    "            #             print(\"expand_size : \", expand_size, \" round : \", 10 + 10 * round_num, \" acc1 : \", acc1 / n, \" acc2 : \",\n",
    "            #                   acc2 / n)\n",
    "            print(\"index : \", landmark_index, \" round : \", 10 + 10 * round_num, \" test1 acc : \", \"%.3f\" % (acc1 / n),\n",
    "                  \"%.3f\" % (acc2 / n), \"%.3f\" % (acc3 / n), \"%.3f\" % (acc4 / n), \"%.3f\" % (acc5 / n),\n",
    "                  \"%.3f\" % (acc6 / n), \"%.3f\" % (acc7 / n), \"%.3f\" % (acc8 / n))\n",
    "\n",
    "            test_images, test_labels = read_images(2)\n",
    "            n = len(test_images)\n",
    "            acc1 = 0\n",
    "            acc2 = 0\n",
    "            acc3 = 0\n",
    "            acc4 = 0\n",
    "            acc5 = 0\n",
    "            acc6 = 0\n",
    "            acc7 = 0\n",
    "            acc8 = 0\n",
    "            # print(test_images[0])\n",
    "            for i in range(n):\n",
    "                x = test_images[i]\n",
    "                #     print(x.shape)\n",
    "                #     start = time()\n",
    "                result = predict(x)\n",
    "                f1, f2, f3, f4, f5, f6, f7, f8 = evaluate_acc(result, test_labels[i])\n",
    "                acc1 += int(f1)\n",
    "                acc2 += int(f2)\n",
    "                acc3 += int(f3)\n",
    "                acc4 += int(f4)\n",
    "                acc5 += int(f5)\n",
    "                acc6 += int(f6)\n",
    "                acc7 += int(f7)\n",
    "                acc8 += int(f8)\n",
    "\n",
    "            #             print(\"expand_size : \", expand_size, \" round : \", 10 + 10 * round_num, \" acc1 : \", acc1 / n, \" acc2 : \",\n",
    "            #                   acc2 / n)\n",
    "            print(\"index : \", landmark_index, \" round : \", 10 + 10 * round_num, \" test2 acc : \", \"%.3f\" % (acc1 / n),\n",
    "                  \"%.3f\" % (acc2 / n), \"%.3f\" % (acc3 / n), \"%.3f\" % (acc4 / n), \"%.3f\" % (acc5 / n),\n",
    "                  \"%.3f\" % (acc6 / n), \"%.3f\" % (acc7 / n), \"%.3f\" % (acc8 / n))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
