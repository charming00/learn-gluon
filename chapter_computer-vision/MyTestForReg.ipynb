{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mxnet import nd\n",
    "import mxnet as mx\n",
    "classes = ['background','p1','p2','p3','p4',\n",
    "           'p5','p6','p7','p8','p9','p10',\n",
    "           'p11','p12','p13','p14','p15',\n",
    "           'p16','p17','p18','p19']\n",
    "# RGB color for each class\n",
    "colormap = [[0,0,0],[128,0,0],[0,128,0], [128,128,0], [0,0,128],\n",
    "            [128,0,128],[0,64,128],[128,128,128],[64,0,0],[192,0,0],\n",
    "            [64,128,0],[192,128,0],[64,0,128],[192,0,128],\n",
    "            [64,128,128],[192,128,128],[0,64,0],[128,64,0],\n",
    "            [0,192,0],[128,192,0]]\n",
    "\n",
    "min_coordinate = [[504,697],[1063,606],[948,888],[286,902],[1079,1191],[1053,1507],[1048,1661],\n",
    "                  [993,1729],[1025,1706],[415,1391],[1121,1355],[1138,1388],[1245,1294],\n",
    "                  [1212,1477],[1170,1152],[1114,1756],[635,1090],[1081,1100],[350,1006]]\n",
    "expand_size = 55\n",
    "landmark_index = 9\n",
    "# len(classes), len(colormap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import image\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from time import time\n",
    "\n",
    "data_root = '../data'\n",
    "image_root = data_root + '/CephalometricLandmark/CroppedImage'\n",
    "# image_root = data_root + '/CephalometricLandmark/ContrastImage1'\n",
    "txt_root = data_root + '/CephalometricLandmark/AnnotationsByMD'\n",
    "\n",
    "\n",
    "def read_images(dataset_num=0):\n",
    "    contrast_size = 0\n",
    "    if dataset_num == 0:\n",
    "        begin_index = 1\n",
    "        end_index = 151\n",
    "        contrast_size = 0\n",
    "    elif dataset_num == 1:\n",
    "        begin_index = 151\n",
    "        end_index = 301\n",
    "    else:\n",
    "        begin_index = 301\n",
    "        end_index = 401\n",
    "\n",
    "    data  = [None] * (end_index - begin_index) * (contrast_size + 1)\n",
    "    label = [None] * (end_index - begin_index) * (contrast_size + 1)\n",
    "    label_int = [None] * (end_index - begin_index) * (contrast_size + 1)\n",
    "    #     expand_label =  [None] * (end_index - begin_index)\n",
    "    #     bounding_box = [[[2000,2000],[0,0],[0,0]] for i in range(19)]\n",
    "    index = 0\n",
    "    for contrast_index in range(contrast_size + 1):\n",
    "#         image_root = data_root + '/CephalometricLandmark/ContrastImage' + str(contrast_index)\n",
    "#         image_root = data_root + '/CephalometricLandmark/GaussianNoise' + str(contrast_index)\n",
    "        for i in range(begin_index, end_index):\n",
    "            image_filename = image_root + \"/%02d/%03d.bmp\" % (landmark_index + 1, i)\n",
    "            txt_filename1 = txt_root + '/400_senior' + \"/%03d.txt\" % i\n",
    "            txt_filename2 = txt_root + '/400_junior' + \"/%03d.txt\" % i\n",
    "            # #         label_image[index] = nd.zeros_like(data[index])\n",
    "\n",
    "            with open(txt_filename1, 'r') as f:\n",
    "                txts = f.read().split()\n",
    "            with open(txt_filename2, 'r') as f:\n",
    "                txts1 = f.read().split()\n",
    "            x = int((int(txts[landmark_index].split(',')[0]) + int(txts1[landmark_index].split(',')[0]))/2) - min_coordinate[landmark_index][0]\n",
    "            y = int((int(txts[landmark_index].split(',')[1]) + int(txts1[landmark_index].split(',')[1]))/2) - min_coordinate[landmark_index][1]\n",
    "            #         label_image[index][y-expand_size:y+expand_size,x-expand_size:x+expand_size] = colormap[landmark_index+1]\n",
    "#             x = int(txts1[landmark_index].split(',')[0])- min_coordinate[landmark_index][0]\n",
    "#             y = int(txts1[landmark_index].split(',')[1])- min_coordinate[landmark_index][1]\n",
    "            minx = x - expand_size\n",
    "            maxx = x + expand_size\n",
    "            if minx < 0:\n",
    "                minx = 0\n",
    "            if maxx >= 640:\n",
    "                maxx = 639\n",
    "\n",
    "            miny = y - expand_size\n",
    "            maxy = y + expand_size\n",
    "            if miny < 0:\n",
    "                miny = 0\n",
    "            if maxy >= 640:\n",
    "                maxy = 639\n",
    "            data[index] = image.imread(image_filename)\n",
    "            label[index] = nd.zeros((data[index].shape[0], data[index].shape[1]))\n",
    "            label[index][miny:maxy, minx:maxx] = 1\n",
    "            label_int[index] = [np.float32(x),np.float32(y)]\n",
    "#             label[index] = nd.flip(label[index],0)\n",
    "#             print(data[index].shape,label[index].shape)\n",
    "            index += 1\n",
    "            \n",
    "    return data, label_int\n",
    "\n",
    "# train_images, train_label_images, train_labels,bounding_boxes= read_images(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imgs = [train_images[0],train_label_images[0]]\n",
    "# # print(bounding_boxes)\n",
    "# # print(type(train_images))\n",
    "# landmarkindex = 2\n",
    "# margin_size = 100\n",
    "# for i in range(19):\n",
    "# #     imgs += [train_images[i][900:1100,800:1000],train_labels[i][990:1050,800:860]]\n",
    "# #     x = train_labels[i][1][0]\n",
    "# #     y = train_labels[i][1][1]\n",
    "# #     size = 40\n",
    "# #     imgs += [train_images[i][y-size:y+size,x-size:x+size],train_label_images[i][y-size:y+size,x-size:x+size]]\n",
    "    \n",
    "#     minx = bounding_boxes[0][0]\n",
    "#     miny = bounding_boxes[0][1]\n",
    "#     maxx = bounding_boxes[1][0]\n",
    "#     maxy = bounding_boxes[1][1]\n",
    "\n",
    "#     imgs += [train_images[i][miny-margin_size:maxy+margin_size,minx-margin_size:maxx+margin_size],train_label_images[i][miny-margin_size:maxy+margin_size,minx-margin_size:maxx+margin_size]]\n",
    "# # print(train_labels[0][981:1001,819:839])\n",
    "# utils.show_images(imgs, nrows=19, ncols=2,figsize=(12,160))\n",
    "# [im.shape for im in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# imgs = []\n",
    "# landmark_index = 0\n",
    "# for i in range(10):\n",
    "#     crop_image = image_crop(train_images[i],bounding_boxes[0],bounding_boxes[1])\n",
    "#     crop_label = image_crop(train_label_images[i],bounding_boxes[0],bounding_boxes[1])\n",
    "#     imgs += [crop_image,crop_label]\n",
    "# utils.show_images(imgs, nrows=10, ncols=2,figsize=(12,160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "import random\n",
    "\n",
    "rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def normalize_image(data):\n",
    "#     mx.random.seed(np.random.randint(1, 1000))\n",
    "#     noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "#     return ((data.astype('float32')+ 10*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "    return (data.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "\n",
    "class VOCSegDataset(gluon.data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_num, crop_size):\n",
    "        self.crop_size = crop_size\n",
    "        self.data, self.label = read_images(dataset_num=dataset_num)\n",
    "        self.data[:] = [normalize_image(im) for im in self.data]\n",
    "#         for i in range(len(self.data)):\n",
    "#             tmp = image_crop(self.data[i], self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "#             self.data[i].reshape(tmp.shape)\n",
    "#             self.data[i] = tmp.transpose((2,0,1))\n",
    "#             tmp = image_crop(self.label_image[i], self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "#             self.label_image[i].reshape(tmp.shape)\n",
    "#             self.label_image[i] = tmp.transpose((2,0,1))\n",
    "#         print('Read '+str(len(self.data))+' examples')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         data,label = image_crop(self.data[idx],self.label[idx],self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "        data = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "#         aug1 = image.HorizontalFlipAug(1)\n",
    "# #         aug2 = image.BrightnessJitterAug(1)\n",
    "# #         aug3 = image.ContrastJitterAug(1)\n",
    "#         if random.random() > 0.5:\n",
    "#         print(data.shape)\n",
    "#         data =  nd.flip(data, axis=0)\n",
    "#         label = nd.flip(label,0)\n",
    "#         data = aug2(data)\n",
    "#         data = aug3(data)\n",
    "            \n",
    "        return data.transpose((2,0,1)), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (640, 640)\n",
    "voc_train = VOCSegDataset(0, input_shape)\n",
    "voc_test1 = VOCSegDataset(1, input_shape)\n",
    "# voc_test2 = VOCSegDataset(2, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 640, 640)\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "train_data = gluon.data.DataLoader(\n",
    "    voc_train, batch_size, shuffle=True,last_batch='discard')\n",
    "test_data = gluon.data.DataLoader(\n",
    "    voc_test1, batch_size,last_batch='discard')\n",
    "\n",
    "for data, label in train_data:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (1, 3, 64, 64)\n",
      "After conv: (1, 10, 32, 32)\n",
      "After transposed conv (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "\n",
    "conv = nn.Conv2D(10, kernel_size=4, padding=1, strides=2)\n",
    "conv_trans = nn.Conv2DTranspose(3, kernel_size=4, padding=1, strides=2)\n",
    "\n",
    "conv.initialize()\n",
    "conv_trans.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(1,3,64,64))\n",
    "y = conv(x)\n",
    "print('Input:', x.shape)\n",
    "print('After conv:', y.shape)\n",
    "print('After transposed conv', conv_trans(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.model_zoo import vision as models\n",
    "pretrained_net = models.resnet50_v2(pretrained=True)\n",
    "\n",
    "# (pretrained_net.features[-4:], pretrained_net.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = nn.HybridSequential()\n",
    "for layer in pretrained_net.features[:-2]:\n",
    "    net.add(layer)\n",
    "\n",
    "# x = nd.random.uniform(shape=(1,3,*input_shape))\n",
    "# print('Input:', x.shape)\n",
    "# print('Output:', net(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(classes)\n",
    "\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Dense(4096),\n",
    "        nn.Dense(2)\n",
    "    )\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros(\n",
    "        (in_channels, out_channels, kernel_size, kernel_size),\n",
    "        dtype='float32')\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return nd.array(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# x = train_images[0]\n",
    "# print('Input', x.shape)\n",
    "# x = x.astype('float32').transpose((2,0,1)).expand_dims(axis=0)/255\n",
    "\n",
    "# conv_trans = nn.Conv2DTranspose(\n",
    "#     3, in_channels=3, kernel_size=8, padding=2, strides=4)\n",
    "# conv_trans.initialize()\n",
    "# conv_trans(x)\n",
    "# conv_trans.weight.set_data(bilinear_kernel(3, 3, 8))\n",
    "\n",
    "\n",
    "# y = conv_trans(x)\n",
    "# y = y[0].clip(0,1).transpose((1,2,0))\n",
    "# print('Output', y.shape)\n",
    "\n",
    "# plt.imshow(y.asnumpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "net[-1].initialize()\n",
    "net[-2].initialize()\n",
    "# conv_trans = net[-1]\n",
    "# conv_trans.initialize(init=init.Zero())\n",
    "# net[-2].initialize(init=init.Xavier())\n",
    "\n",
    "# x = nd.zeros((batch_size, 3, *input_shape))\n",
    "# net(x)\n",
    "\n",
    "# shape = conv_trans.weight.data().shape\n",
    "# conv_trans.weight.set_data(bilinear_kernel(*shape[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.9 sec\n",
      "Epoch 1. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.8 sec\n",
      "Epoch 2. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.9 sec\n",
      "Epoch 3. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.8 sec\n",
      "Epoch 4. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.8 sec\n",
      "Epoch 5. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.9 sec\n",
      "Epoch 6. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.9 sec\n",
      "Epoch 7. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.9 sec\n",
      "Epoch 8. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.9 sec\n",
      "Epoch 9. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.9 sec\n",
      "Epoch 10. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.8 sec\n",
      "Epoch 11. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.8 sec\n",
      "Epoch 12. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.0 sec\n",
      "Epoch 13. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.9 sec\n",
      "Epoch 14. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.8 sec\n",
      "Epoch 15. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.9 sec\n",
      "Epoch 16. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.0 sec\n",
      "Epoch 17. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.0 sec\n",
      "Epoch 18. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.0 sec\n",
      "Epoch 19. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.0 sec\n",
      "Epoch 20. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.9 sec\n",
      "Epoch 21. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.1 sec\n",
      "Epoch 22. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.1 sec\n",
      "Epoch 23. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.0 sec\n",
      "Epoch 24. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.0 sec\n",
      "Epoch 25. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.1 sec\n",
      "Epoch 26. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.1 sec\n",
      "Epoch 27. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.8 sec\n",
      "Epoch 28. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 4.0 sec\n",
      "Epoch 29. Loss: 0.000, Train acc 0.00, Test acc 0.00, Time 3.9 sec\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "# loss = gluon.loss.SoftmaxCrossEntropyLoss(axis=1)\n",
    "# loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "def my_loss(pre,label):\n",
    "    print(pre.shape)\n",
    "    print(pre[0][0])\n",
    "    print(label.shape)\n",
    "    print(label)\n",
    "    return 0\n",
    "loss = gluon.loss.L2Loss()\n",
    "# loss = my_loss\n",
    "\n",
    "\n",
    "\n",
    "ctx = utils.try_all_gpus()\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        'NAG', {'learning_rate': 0.1, 'wd':1e-3})\n",
    "\n",
    "utils.mytrain(train_data, test_data, net, loss,\n",
    "            trainer, ctx, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "# def predict(im):\n",
    "# #     mx.random.seed(np.random.randint(1, 1000))\n",
    "# #     noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "# #     data = ((im.astype('float32')+ 5*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "#     data = normalize_image(im)\n",
    "# #     data = (im.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "#     data = data.transpose((2,0,1)).expand_dims(axis=0)\n",
    "#     yhat = net(data.as_in_context(ctx[0]))\n",
    "#     pred = nd.argmax(yhat, axis=1)\n",
    "#     return pred.reshape((pred.shape[1], pred.shape[2]))\n",
    "\n",
    "def predict(im):\n",
    "#     mx.random.seed(np.random.randint(1, 1000))\n",
    "#     noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "#     data = ((im.astype('float32')+ 5*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "    data = normalize_image(im)\n",
    "#     data = (im.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "    data = data.transpose((2,0,1)).expand_dims(axis=0)\n",
    "    yhat = net(data.as_in_context(ctx[0]))\n",
    "    \n",
    "    return yhat\n",
    "\n",
    "def label2image(pred):\n",
    "    x = pred.astype('int32').asnumpy()\n",
    "    cm = nd.array(colormap).astype('uint8')\n",
    "    return nd.array(cm[x,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images,test_labels = read_images(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_acc(result, label):\n",
    "    if(len(np.where(result.asnumpy()>0)[1]) ==0):\n",
    "        return False,False,False,False,False,False,False,False\n",
    "    result_maxx = np.max(np.where(result.asnumpy()>0)[1])\n",
    "    result_minx = np.min(np.where(result.asnumpy()>0)[1])\n",
    "    result_maxy = np.max(np.where(result.asnumpy()>0)[0])\n",
    "    result_miny = np.min(np.where(result.asnumpy()>0)[0])\n",
    "\n",
    "    result_centerx = int((result_maxx + result_minx)/2)\n",
    "    result_centery = int((result_maxy + result_miny)/2)\n",
    "    \n",
    "    result_avgx = np.average(np.where(result.asnumpy()>0)[1])\n",
    "    result_avgy = np.average(np.where(result.asnumpy()>0)[0])\n",
    "\n",
    "    label_maxx = np.max(np.where(label.asnumpy()>0)[1])\n",
    "    label_minx = np.min(np.where(label.asnumpy()>0)[1])\n",
    "    label_maxy = np.max(np.where(label.asnumpy()>0)[0])\n",
    "    label_miny = np.min(np.where(label.asnumpy()>0)[0])\n",
    "    \n",
    "    label_centerx = int((label_maxx + label_minx)/2)\n",
    "    label_centery = int((label_maxy + label_miny)/2)\n",
    "    \n",
    "    lable_avgx = np.average(np.where(label.asnumpy()>0)[1])\n",
    "    lable_avgy = np.average(np.where(label.asnumpy()>0)[0])\n",
    "    \n",
    "    d1 = pow((result_centerx - label_centerx),2) + pow((result_centery - label_centery),2)\n",
    "    d2 = pow((result_avgx - label_centerx),2) + pow((result_avgy - label_centery),2)\n",
    "#     print(\"============================\")\n",
    "#     print(np.where(result.asnumpy()>0))\n",
    "#     print(result_centerx,label_centerx)\n",
    "#     print(result_centery,label_centery)\n",
    "#     print(d1,d2)\n",
    "    return (d1 < 400, d2 < 400, d1 < 625, d2 < 625, d1 < 900, d2 < 900, d1 < 1600, d2 < 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[22:56:34] src/storage/./pooled_storage_manager.h:108: cudaMalloc failed: out of memory\n\nStack trace returned 10 entries:\n[bt] (0) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x32173a) [0x7f664e6a473a]\n[bt] (1) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x321d61) [0x7f664e6a4d61]\n[bt] (2) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x297d083) [0x7f6650d00083]\n[bt] (3) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2981935) [0x7f6650d04935]\n[bt] (4) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x26ab94a) [0x7f6650a2e94a]\n[bt] (5) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x26bfc5a) [0x7f6650a42c5a]\n[bt] (6) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x26bfd8b) [0x7f6650a42d8b]\n[bt] (7) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x24f6a04) [0x7f6650879a04]\n[bt] (8) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x24fced3) [0x7f665087fed3]\n[bt] (9) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x24fd126) [0x7f6650880126]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-44d999c6e10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     start = time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0macc1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"\"\"Returns a string representation of the array.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mshape_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         return '\\n%s\\n<%s %s @%s>' % (str(self.asnumpy()),\n\u001b[0m\u001b[1;32m    190\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                                       shape_info, self.context)\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \"\"\"\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [22:56:34] src/storage/./pooled_storage_manager.h:108: cudaMalloc failed: out of memory\n\nStack trace returned 10 entries:\n[bt] (0) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x32173a) [0x7f664e6a473a]\n[bt] (1) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x321d61) [0x7f664e6a4d61]\n[bt] (2) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x297d083) [0x7f6650d00083]\n[bt] (3) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2981935) [0x7f6650d04935]\n[bt] (4) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x26ab94a) [0x7f6650a2e94a]\n[bt] (5) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x26bfc5a) [0x7f6650a42c5a]\n[bt] (6) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x26bfd8b) [0x7f6650a42d8b]\n[bt] (7) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x24f6a04) [0x7f6650879a04]\n[bt] (8) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x24fced3) [0x7f665087fed3]\n[bt] (9) /home/charming/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x24fd126) [0x7f6650880126]\n\n"
     ]
    }
   ],
   "source": [
    "# n = len(test_images)\n",
    "n = 10\n",
    "imgs = []\n",
    "acc1 = 0\n",
    "acc2 = 0\n",
    "acc3 = 0\n",
    "acc4 = 0\n",
    "acc5 = 0\n",
    "acc6 = 0\n",
    "acc7 = 0\n",
    "acc8 = 0\n",
    "# print(test_images[0])\n",
    "for i in range(n):\n",
    "    x = test_images[i]\n",
    "#     print(x.shape)\n",
    "#     start = time()\n",
    "    result = predict(x)\n",
    "    print(result)\n",
    "    f1,f2,f3,f4,f5,f6,f7,f8 = evaluate_acc(result,test_labels[i])\n",
    "    acc1 += int(f1)\n",
    "    acc2 += int(f2)\n",
    "    acc3 += int(f3)\n",
    "    acc4 += int(f4)\n",
    "    acc5 += int(f5)\n",
    "    acc6 += int(f6)\n",
    "    acc7 += int(f7)\n",
    "    acc8 += int(f8)\n",
    "\n",
    "#     print(type(np.where(result.asnumpy()>0)[0]))\n",
    "#     print(np.where(test_labels[i].asnumpy()>0))\n",
    "    pred = label2image(predict(x))\n",
    "    imgs += [x, pred, label2image(test_labels[i])]\n",
    "print(acc1/n,\"  \", acc2/n,\"  \", acc3/n,\"  \", acc4/n,\"  \", acc5/n,\"  \", acc6/n,\"  \", acc7/n,\"  \", acc8/n)\n",
    "utils.show_images(imgs, nrows=n, ncols=3, figsize=(6,20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_images,test_labels = read_images(18,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n = 10\n",
    "# imgs = []\n",
    "# for i in range(n):\n",
    "#     x = test_images[i]\n",
    "#     imgs += [x, label2image(test_labels[i]), label2image(test_labels[i])]\n",
    "# # \n",
    "# utils.show_images(imgs, nrows=n, ncols=3, figsize=(6,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
