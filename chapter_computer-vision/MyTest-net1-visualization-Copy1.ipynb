{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import image\n",
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn,Block\n",
    "from mxnet import init\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from time import time\n",
    "\n",
    "classes = ['background','p1','p2','p3','p4',\n",
    "           'p5','p6','p7','p8','p9','p10',\n",
    "           'p11','p12','p13','p14','p15',\n",
    "           'p16','p17','p18','p19']\n",
    "# RGB color for each class\n",
    "colormap = [[0,0,0],[128,0,0],[0,128,0], [128,128,0], [0,0,128],\n",
    "            [128,0,128],[0,64,128],[128,128,128],[64,0,0],[192,0,0],\n",
    "            [64,128,0],[192,128,0],[64,0,128],[192,0,128],\n",
    "            [64,128,128],[192,128,128],[0,64,0],[128,64,0],\n",
    "            [0,192,0],[128,192,0]]\n",
    "\n",
    "min_coordinate = [[504,697],[1063,606],[948,888],[286,902],[1079,1191],[1053,1507],[1048,1661],\n",
    "                  [993,1729],[1025,1706],[415,1391],[1121,1355],[1138,1388],[1245,1294],\n",
    "                  [1212,1477],[1170,1152],[1114,1756],[635,1090],[1081,1100],[350,1006]]\n",
    "expand_size = 55\n",
    "landmark_index = 9\n",
    "# len(classes), len(colormap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import image\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from time import time\n",
    "\n",
    "data_root = '../data'\n",
    "image_root = data_root + '/CephalometricLandmark/CroppedImage'\n",
    "# image_root = data_root + '/CephalometricLandmark/ContrastImage1'\n",
    "txt_root = data_root + '/CephalometricLandmark/AnnotationsByMD'\n",
    "model_params_root = data_root + '/CephalometricLandmark/model_params'\n",
    "\n",
    "\n",
    "def read_images(dataset_num=0):\n",
    "    contrast_size = 0\n",
    "    if dataset_num == 0:\n",
    "        begin_index = 1\n",
    "        end_index = 151\n",
    "        contrast_size = 0\n",
    "    elif dataset_num == 1:\n",
    "        begin_index = 151\n",
    "        end_index = 301\n",
    "    else:\n",
    "        begin_index = 301\n",
    "        end_index = 401\n",
    "\n",
    "    data, label = [None] * (end_index - begin_index) * (contrast_size + 1), [None] * (end_index - begin_index) * (\n",
    "            contrast_size + 1)\n",
    "    #     expand_label =  [None] * (end_index - begin_index)\n",
    "    #     bounding_box = [[[2000,2000],[0,0],[0,0]] for i in range(19)]\n",
    "    index = 0\n",
    "    for contrast_index in range(contrast_size + 1):\n",
    "#         image_root = data_root + '/CephalometricLandmark/ContrastImage' + str(contrast_index)\n",
    "#         image_root = data_root + '/CephalometricLandmark/GaussianNoise' + str(contrast_index)\n",
    "        for i in range(begin_index, end_index):\n",
    "            image_filename = image_root + \"/%02d/%03d.bmp\" % (landmark_index + 1, i)\n",
    "            txt_filename2 = txt_root + '/400_junior' + \"/%03d.txt\" % i\n",
    "            # #         label_image[index] = nd.zeros_like(data[index])\n",
    "\n",
    "            with open(txt_filename2, 'r') as f:\n",
    "                txts1 = f.read().split()\n",
    "            x = int(txts1[landmark_index].split(',')[0]) - min_coordinate[landmark_index][0]\n",
    "            y = int(txts1[landmark_index].split(',')[1]) - min_coordinate[landmark_index][1]\n",
    "            #         label_image[index][y-expand_size:y+expand_size,x-expand_size:x+expand_size] = colormap[landmark_index+1]\n",
    "#             x = int(txts1[landmark_index].split(',')[0])- min_coordinate[landmark_index][0]\n",
    "#             y = int(txts1[landmark_index].split(',')[1])- min_coordinate[landmark_index][1]\n",
    "            minx = x - expand_size\n",
    "            maxx = x + expand_size\n",
    "            if minx < 0:\n",
    "                minx = 0\n",
    "            if maxx >= 640:\n",
    "                maxx = 639\n",
    "\n",
    "            miny = y - expand_size\n",
    "            maxy = y + expand_size\n",
    "            if miny < 0:\n",
    "                miny = 0\n",
    "            if maxy >= 640:\n",
    "                maxy = 639\n",
    "            data[index] = image.imread(image_filename)\n",
    "            label[index] = nd.zeros((data[index].shape[0], data[index].shape[1]))\n",
    "            label[index][miny:maxy, minx:maxx] = 1\n",
    "#             label[index] = nd.flip(label[index],0)\n",
    "#             print(data[index].shape,label[index].shape)\n",
    "            index += 1\n",
    "            \n",
    "    return data, label\n",
    "\n",
    "# train_images, train_label_images, train_labels,bounding_boxes= read_images(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imgs = [train_images[0],train_label_images[0]]\n",
    "# # print(bounding_boxes)\n",
    "# # print(type(train_images))\n",
    "# landmarkindex = 2\n",
    "# margin_size = 100\n",
    "# for i in range(19):\n",
    "# #     imgs += [train_images[i][900:1100,800:1000],train_labels[i][990:1050,800:860]]\n",
    "# #     x = train_labels[i][1][0]\n",
    "# #     y = train_labels[i][1][1]\n",
    "# #     size = 40\n",
    "# #     imgs += [train_images[i][y-size:y+size,x-size:x+size],train_label_images[i][y-size:y+size,x-size:x+size]]\n",
    "    \n",
    "#     minx = bounding_boxes[0][0]\n",
    "#     miny = bounding_boxes[0][1]\n",
    "#     maxx = bounding_boxes[1][0]\n",
    "#     maxy = bounding_boxes[1][1]\n",
    "\n",
    "#     imgs += [train_images[i][miny-margin_size:maxy+margin_size,minx-margin_size:maxx+margin_size],train_label_images[i][miny-margin_size:maxy+margin_size,minx-margin_size:maxx+margin_size]]\n",
    "# # print(train_labels[0][981:1001,819:839])\n",
    "# utils.show_images(imgs, nrows=19, ncols=2,figsize=(12,160))\n",
    "# [im.shape for im in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# imgs = []\n",
    "# landmark_index = 0\n",
    "# for i in range(10):\n",
    "#     crop_image = image_crop(train_images[i],bounding_boxes[0],bounding_boxes[1])\n",
    "#     crop_label = image_crop(train_label_images[i],bounding_boxes[0],bounding_boxes[1])\n",
    "#     imgs += [crop_image,crop_label]\n",
    "# utils.show_images(imgs, nrows=10, ncols=2,figsize=(12,160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "import random\n",
    "\n",
    "rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def normalize_image(data):\n",
    "#     mx.random.seed(np.random.randint(1, 1000))\n",
    "#     noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "#     return ((data.astype('float32')+ 10*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "    return (data.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "\n",
    "class VOCSegDataset(gluon.data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_num, crop_size):\n",
    "        self.crop_size = crop_size\n",
    "        self.data, self.label = read_images(dataset_num=dataset_num)\n",
    "        self.data[:] = [normalize_image(im) for im in self.data]\n",
    "#         for i in range(len(self.data)):\n",
    "#             tmp = image_crop(self.data[i], self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "#             self.data[i].reshape(tmp.shape)\n",
    "#             self.data[i] = tmp.transpose((2,0,1))\n",
    "#             tmp = image_crop(self.label_image[i], self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "#             self.label_image[i].reshape(tmp.shape)\n",
    "#             self.label_image[i] = tmp.transpose((2,0,1))\n",
    "#         print('Read '+str(len(self.data))+' examples')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         data,label = image_crop(self.data[idx],self.label[idx],self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "        data = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "#         aug1 = image.HorizontalFlipAug(1)\n",
    "# #         aug2 = image.BrightnessJitterAug(1)\n",
    "# #         aug3 = image.ContrastJitterAug(1)\n",
    "#         if random.random() > 0.5:\n",
    "#         print(data.shape)\n",
    "#         data =  nd.flip(data, axis=0)\n",
    "#         label = nd.flip(label,0)\n",
    "#         data = aug2(data)\n",
    "#         data = aug3(data)\n",
    "            \n",
    "        return data.transpose((2,0,1)), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (640, 640)\n",
    "voc_train = VOCSegDataset(0, input_shape)\n",
    "voc_test1 = VOCSegDataset(1, input_shape)\n",
    "# voc_test2 = VOCSegDataset(2, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 640, 640)\n",
      "(4, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "train_data = gluon.data.DataLoader(\n",
    "    voc_train, batch_size, shuffle=True,last_batch='discard')\n",
    "test_data = gluon.data.DataLoader(\n",
    "    voc_test1, batch_size,last_batch='discard')\n",
    "\n",
    "for data, label in train_data:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (1, 3, 64, 64)\n",
      "After conv: (1, 10, 32, 32)\n",
      "After transposed conv (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn,Block\n",
    "from mxnet import nd\n",
    "\n",
    "conv = nn.Conv2D(10, kernel_size=4, padding=1, strides=2)\n",
    "conv_trans = nn.Conv2DTranspose(3, kernel_size=4, padding=1, strides=2)\n",
    "\n",
    "conv.initialize()\n",
    "conv_trans.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(1,3,64,64))\n",
    "y = conv(x)\n",
    "print('Input:', x.shape)\n",
    "print('After conv:', y.shape)\n",
    "print('After transposed conv', conv_trans(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.model_zoo import vision as models\n",
    "pretrained_net = models.densenet121(pretrained=True)\n",
    "\n",
    "# (pretrained_net.features[-4:], pretrained_net.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = nn.HybridSequential()\n",
    "for layer in pretrained_net.features[:-2]:\n",
    "    net.add(layer)\n",
    "\n",
    "# x = nd.random.uniform(shape=(1,3,*input_shape))\n",
    "# print('Input:', x.shape)\n",
    "# print('Output:', net(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridSequential(\n",
      "  (0): Conv2D(3 -> 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "  (2): Activation(relu)\n",
      "  (3): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(1, 1), ceil_mode=False)\n",
      "  (4): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(64 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=96)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(96 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=160)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(160 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=192)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(192 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=224)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(224 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (5): HybridSequential(\n",
      "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "    (1): Activation(relu)\n",
      "    (2): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): AvgPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (6): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=160)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(160 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=192)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(192 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=224)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(224 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=288)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(288 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=320)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(320 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (7): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=352)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(352 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (8): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=384)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(384 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (9): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=416)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(416 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (10): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=448)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(448 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (11): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=480)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(480 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (7): HybridSequential(\n",
      "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (1): Activation(relu)\n",
      "    (2): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): AvgPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (8): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=288)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(288 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=320)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(320 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=352)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(352 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=384)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(384 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=416)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(416 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=448)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(448 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (7): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=480)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(480 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (8): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (9): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=544)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(544 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (10): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=576)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(576 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (11): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=608)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(608 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (12): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=640)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(640 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (13): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=672)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(672 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (14): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=704)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(704 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (15): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=736)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(736 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (16): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=768)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(768 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (17): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=800)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(800 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (18): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=832)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(832 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (19): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=864)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(864 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (20): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=896)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(896 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (21): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=928)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(928 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (22): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=960)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(960 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (23): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=992)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(992 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (9): HybridSequential(\n",
      "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "    (1): Activation(relu)\n",
      "    (2): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): AvgPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (10): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=544)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(544 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=576)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(576 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=608)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(608 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=640)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(640 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=672)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(672 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=704)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(704 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (7): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=736)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(736 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (8): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=768)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(768 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (9): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=800)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(800 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (10): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=832)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(832 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (11): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=864)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(864 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (12): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=896)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(896 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (13): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=928)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(928 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (14): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=960)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(960 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (15): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=992)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(992 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (11): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "  (12): Activation(relu)\n",
      "  (13): Conv2D(None -> 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (14): Conv2DTranspose(2 -> 0, kernel_size=(64, 64), stride=(32, 32), padding=(16, 16))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(classes)\n",
    "\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Conv2D(2, kernel_size=1),\n",
    "        nn.Conv2DTranspose(2, kernel_size=64, padding=16,strides=32)\n",
    "    )\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros(\n",
    "        (in_channels, out_channels, kernel_size, kernel_size),\n",
    "        dtype='float32')\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return nd.array(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# x = train_images[0]\n",
    "# print('Input', x.shape)\n",
    "# x = x.astype('float32').transpose((2,0,1)).expand_dims(axis=0)/255\n",
    "\n",
    "# conv_trans = nn.Conv2DTranspose(\n",
    "#     3, in_channels=3, kernel_size=8, padding=2, strides=4)\n",
    "# conv_trans.initialize()\n",
    "# conv_trans(x)\n",
    "# conv_trans.weight.set_data(bilinear_kernel(3, 3, 8))\n",
    "\n",
    "\n",
    "# y = conv_trans(x)\n",
    "# y = y[0].clip(0,1).transpose((1,2,0))\n",
    "# print('Output', y.shape)\n",
    "\n",
    "# plt.imshow(y.asnumpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "\n",
    "conv_trans = net[-1]\n",
    "conv_trans.initialize(init=init.Zero())\n",
    "net[-2].initialize(init=init.Xavier())\n",
    "\n",
    "x = nd.zeros((batch_size, 3, *input_shape))\n",
    "net(x)\n",
    "\n",
    "shape = conv_trans.weight.data().shape\n",
    "conv_trans.weight.set_data(bilinear_kernel(*shape[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctx = utils.try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss(axis=1)\n",
    "# loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "\n",
    "ctx = utils.try_all_gpus()\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        'SGD', {'learning_rate': 0.1, 'wd':1e-3})\n",
    "\n",
    "utils.train(train_data, test_data, net, loss,\n",
    "            trainer, ctx, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.save_params(model_params_root + \"/net1-mark10-resnet18-epochs100.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b9cefbadc521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnet2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXavier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtry_all_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_params_root\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/net1-mark10-resnet18-epochs100.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtry_all_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mload_params\u001b[0;34m(self, filename, ctx, allow_missing, ignore_extra)\u001b[0m\n\u001b[1;32m    346\u001b[0m                     \u001b[0;34m\"Parameter '%s' is missing in file '%s', which contains parameters: %s. \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                     \"Set allow_missing=True to ignore missing parameters.\"%(\n\u001b[0;32m--> 348\u001b[0;31m                         name, filename, _brief_print_list(loaded.keys()))\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_extra\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/utils.py\u001b[0m in \u001b[0;36m_brief_print_list\u001b[0;34m(lst, limit)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;34m\"\"\"Print at most `limit` elements of list.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_brief_print_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', ..., '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0m_brief_print_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"'%s'\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "net2 = nn.HybridSequential()\n",
    "for layer in pretrained_net.features[:-2]:\n",
    "    net2.add(layer)\n",
    "with net2.name_scope():\n",
    "    net2.add(\n",
    "        nn.Conv2D(2, kernel_size=1),\n",
    "        nn.Conv2DTranspose(2, kernel_size=64, padding=16,strides=32)\n",
    "    )\n",
    "net2[-1].initialize(init=init.Zero())\n",
    "net2[-2].initialize(init=init.Xavier())\n",
    "net2.collect_params().reset_ctx(utils.try_all_gpus())\n",
    "net2.load_params(filename = model_params_root + '/net1-mark10-resnet18-epochs100.json',ctx = utils.try_all_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "def predict(im):\n",
    "#     mx.random.seed(np.random.randint(1, 1000))\n",
    "#     noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "#     data = ((im.astype('float32')+ 5*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "    data = normalize_image(im)\n",
    "#     data = (im.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "    data = data.transpose((2,0,1)).expand_dims(axis=0)\n",
    "    yhat = net(data.as_in_context(ctx[0]))\n",
    "    pred = nd.argmax(yhat, axis=1)\n",
    "    return pred.reshape((pred.shape[1], pred.shape[2]))\n",
    "\n",
    "def label2image(pred):\n",
    "    x = pred.astype('int32').asnumpy()\n",
    "    cm = nd.array(colormap).astype('uint8')\n",
    "    return nd.array(cm[x,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images,test_labels = read_images(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_acc(result, label):\n",
    "    if(len(np.where(result.asnumpy()>0)[1]) ==0):\n",
    "        return False,False,False,False,False,False,False,False\n",
    "    result_maxx = np.max(np.where(result.asnumpy()>0)[1])\n",
    "    result_minx = np.min(np.where(result.asnumpy()>0)[1])\n",
    "    result_maxy = np.max(np.where(result.asnumpy()>0)[0])\n",
    "    result_miny = np.min(np.where(result.asnumpy()>0)[0])\n",
    "\n",
    "    result_centerx = int((result_maxx + result_minx)/2)\n",
    "    result_centery = int((result_maxy + result_miny)/2)\n",
    "    \n",
    "    result_avgx = np.average(np.where(result.asnumpy()>0)[1])\n",
    "    result_avgy = np.average(np.where(result.asnumpy()>0)[0])\n",
    "\n",
    "    label_maxx = np.max(np.where(label.asnumpy()>0)[1])\n",
    "    label_minx = np.min(np.where(label.asnumpy()>0)[1])\n",
    "    label_maxy = np.max(np.where(label.asnumpy()>0)[0])\n",
    "    label_miny = np.min(np.where(label.asnumpy()>0)[0])\n",
    "    \n",
    "    label_centerx = int((label_maxx + label_minx)/2)\n",
    "    label_centery = int((label_maxy + label_miny)/2)\n",
    "    \n",
    "    lable_avgx = np.average(np.where(label.asnumpy()>0)[1])\n",
    "    lable_avgy = np.average(np.where(label.asnumpy()>0)[0])\n",
    "    \n",
    "    d1 = pow((result_centerx - label_centerx),2) + pow((result_centery - label_centery),2)\n",
    "    d2 = pow((result_avgx - label_centerx),2) + pow((result_avgy - label_centery),2)\n",
    "#     print(\"============================\")\n",
    "#     print(np.where(result.asnumpy()>0))\n",
    "#     print(result_centerx,label_centerx)\n",
    "#     print(result_centery,label_centery)\n",
    "#     print(d1,d2)\n",
    "    return (d1 < 400, d2 < 400, d1 < 625, d2 < 625, d1 < 900, d2 < 900, d1 < 1600, d2 < 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67    0.67    0.79    0.79    0.89    0.9    0.92    0.92\n"
     ]
    }
   ],
   "source": [
    "# n = len(test_images)\n",
    "n = 100\n",
    "imgs = []\n",
    "acc1 = 0\n",
    "acc2 = 0\n",
    "acc3 = 0\n",
    "acc4 = 0\n",
    "acc5 = 0\n",
    "acc6 = 0\n",
    "acc7 = 0\n",
    "acc8 = 0\n",
    "# print(test_images[0])\n",
    "for i in range(n):\n",
    "    x = test_images[i]\n",
    "#     print(x.shape)\n",
    "#     start = time()\n",
    "    result = predict(x)\n",
    "    f1,f2,f3,f4,f5,f6,f7,f8 = evaluate_acc(result,test_labels[i])\n",
    "    acc1 += int(f1)\n",
    "    acc2 += int(f2)\n",
    "    acc3 += int(f3)\n",
    "    acc4 += int(f4)\n",
    "    acc5 += int(f5)\n",
    "    acc6 += int(f6)\n",
    "    acc7 += int(f7)\n",
    "    acc8 += int(f8)\n",
    "\n",
    "#     print(type(np.where(result.asnumpy()>0)[0]))\n",
    "#     print(np.where(test_labels[i].asnumpy()>0))\n",
    "    pred = label2image(predict(x))\n",
    "    imgs += [x, pred, label2image(test_labels[i])]\n",
    "print(acc1/n,\"  \", acc2/n,\"  \", acc3/n,\"  \", acc4/n,\"  \", acc5/n,\"  \", acc6/n,\"  \", acc7/n,\"  \", acc8/n)\n",
    "# utils.show_images(imgs, nrows=n, ncols=3, figsize=(6,20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_images,test_labels = read_images(18,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n = 10\n",
    "# imgs = []\n",
    "# for i in range(n):\n",
    "#     x = test_images[i]\n",
    "#     imgs += [x, label2image(test_labels[i]), label2image(test_labels[i])]\n",
    "# # \n",
    "# utils.show_images(imgs, nrows=n, ncols=3, figsize=(6,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
