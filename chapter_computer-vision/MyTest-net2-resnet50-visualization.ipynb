{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mxnet import nd\n",
    "import mxnet as mx\n",
    "classes = ['background','p1','p2','p3','p4',\n",
    "           'p5','p6','p7','p8','p9','p10',\n",
    "           'p11','p12','p13','p14','p15',\n",
    "           'p16','p17','p18','p19']\n",
    "# RGB color for each class\n",
    "colormap = [[0,0,0],[128,0,0],[0,128,0], [128,128,0], [0,0,128],\n",
    "            [128,0,128],[0,64,128],[128,128,128],[64,0,0],[192,0,0],\n",
    "            [64,128,0],[192,128,0],[64,0,128],[192,0,128],\n",
    "            [64,128,128],[192,128,128],[0,64,0],[128,64,0],\n",
    "            [0,192,0],[128,192,0]]\n",
    "\n",
    "min_coordinate = [[504,697],[1063,606],[948,888],[286,902],[1079,1191],[1053,1507],[1048,1661],\n",
    "                  [993,1729],[1025,1706],[415,1391],[1121,1355],[1138,1388],[1245,1294],\n",
    "                  [1212,1477],[1170,1152],[1114,1756],[635,1090],[1081,1100],[350,1006]]\n",
    "expand_size = 24\n",
    "\n",
    "landmark_index = 12\n",
    "\n",
    "# len(classes), len(colormap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import image\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from time import time\n",
    "\n",
    "data_root = '../data'\n",
    "image_root = data_root + '/CephalometricLandmark/PredictCroppedImage'\n",
    "# image_root = data_root + '/CephalometricLandmark/ContrastImage1'\n",
    "txt_root = data_root + '/CephalometricLandmark/AnnotationsByMD'\n",
    "\n",
    "\n",
    "def read_images(dataset_num=0):\n",
    "    contrast_size = 0\n",
    "    if dataset_num == 0:\n",
    "        begin_index = 1\n",
    "        end_index = 151\n",
    "        contrast_size = 0\n",
    "    elif dataset_num == 1:\n",
    "        begin_index = 151\n",
    "        end_index = 301\n",
    "    else:\n",
    "        begin_index = 301\n",
    "        end_index = 401\n",
    "\n",
    "    data, label = [None] * (end_index - begin_index) * (contrast_size + 1), [None] * (end_index - begin_index) * (\n",
    "            contrast_size + 1)\n",
    "    #     expand_label =  [None] * (end_index - begin_index)\n",
    "    #     bounding_box = [[[2000,2000],[0,0],[0,0]] for i in range(19)]\n",
    "    index = 0\n",
    "    for contrast_index in range(contrast_size + 1):\n",
    "#         image_root = data_root + '/CephalometricLandmark/ContrastImage' + str(contrast_index)\n",
    "#         image_root = data_root + '/CephalometricLandmark/GaussianNoise' + str(contrast_index)\n",
    "        for i in range(begin_index, end_index):\n",
    "            image_filename = image_root + \"/%02d/%03d.bmp\" % (landmark_index + 1, i)\n",
    "            txt_filename1 = txt_root + '/400_junior' + \"/%03d.txt\" % i\n",
    "            txt_filename2 = txt_root + '/400_predict_average' + \"/%03d.txt\" % i\n",
    "            # #         label_image[index] = nd.zeros_like(data[index])\n",
    "\n",
    "            with open(txt_filename1, 'r') as f:\n",
    "                txts = f.read().split()\n",
    "            with open(txt_filename2, 'r') as f:\n",
    "                txts1 = f.read().split()\n",
    "#             x = int((int(txts[landmark_index].split(',')[0]) + int(txts1[landmark_index].split(',')[0]))/2) - min_coordinate[landmark_index][0]\n",
    "#             y = int((int(txts[landmark_index].split(',')[1]) + int(txts1[landmark_index].split(',')[1]))/2) - min_coordinate[landmark_index][1]\n",
    "            #         label_image[index][y-expand_size:y+expand_size,x-expand_size:x+expand_size] = colormap[landmark_index+1]\n",
    "            x = int(txts[landmark_index].split(',')[0])- int(txts1[landmark_index].split(',')[0]) + 32\n",
    "            y = int(txts[landmark_index].split(',')[1])- int(txts1[landmark_index].split(',')[1]) + 32\n",
    "            minx = x - expand_size\n",
    "            maxx = x + expand_size\n",
    "            if minx < 0:\n",
    "                minx = 0\n",
    "            if minx >= 64:\n",
    "                minx = 63\n",
    "            if maxx < 0:\n",
    "                maxx = 0\n",
    "            if maxx >= 64:\n",
    "                maxx = 63\n",
    "\n",
    "            miny = y - expand_size\n",
    "            maxy = y + expand_size\n",
    "            if miny < 0:\n",
    "                miny = 0\n",
    "            if miny >= 64:\n",
    "                miny = 63\n",
    "            if maxy < 0:\n",
    "                maxy = 0\n",
    "            if maxy >= 64:\n",
    "                maxy = 63\n",
    "            data[index] = image.imread(image_filename)\n",
    "            label[index] = nd.zeros((data[index].shape[0], data[index].shape[1]))\n",
    "#             print(label[index].shape)\n",
    "#             print(miny,maxy,minx,maxx)\n",
    "            if miny != maxy and minx != maxx:\n",
    "                label[index][miny:maxy, minx:maxx] = 1\n",
    "#             label[index] = nd.flip(label[index],0)\n",
    "#             print(data[index].shape,label[index].shape)\n",
    "            index += 1\n",
    "            \n",
    "    return data, label\n",
    "\n",
    "# train_images, train_label_images, train_labels,bounding_boxes= read_images(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imgs = [train_images[0],train_label_images[0]]\n",
    "# # print(bounding_boxes)\n",
    "# # print(type(train_images))\n",
    "# landmarkindex = 2\n",
    "# margin_size = 100\n",
    "# for i in range(19):\n",
    "# #     imgs += [train_images[i][900:1100,800:1000],train_labels[i][990:1050,800:860]]\n",
    "# #     x = train_labels[i][1][0]\n",
    "# #     y = train_labels[i][1][1]\n",
    "# #     size = 40\n",
    "# #     imgs += [train_images[i][y-size:y+size,x-size:x+size],train_label_images[i][y-size:y+size,x-size:x+size]]\n",
    "    \n",
    "#     minx = bounding_boxes[0][0]\n",
    "#     miny = bounding_boxes[0][1]\n",
    "#     maxx = bounding_boxes[1][0]\n",
    "#     maxy = bounding_boxes[1][1]\n",
    "\n",
    "#     imgs += [train_images[i][miny-margin_size:maxy+margin_size,minx-margin_size:maxx+margin_size],train_label_images[i][miny-margin_size:maxy+margin_size,minx-margin_size:maxx+margin_size]]\n",
    "# # print(train_labels[0][981:1001,819:839])\n",
    "# utils.show_images(imgs, nrows=19, ncols=2,figsize=(12,160))\n",
    "# [im.shape for im in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# imgs = []\n",
    "# landmark_index = 0\n",
    "# for i in range(10):\n",
    "#     crop_image = image_crop(train_images[i],bounding_boxes[0],bounding_boxes[1])\n",
    "#     crop_label = image_crop(train_label_images[i],bounding_boxes[0],bounding_boxes[1])\n",
    "#     imgs += [crop_image,crop_label]\n",
    "# utils.show_images(imgs, nrows=10, ncols=2,figsize=(12,160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "import random\n",
    "\n",
    "rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def normalize_image(data):\n",
    "#     mx.random.seed(np.random.randint(1, 1000))\n",
    "#     noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "#     return ((data.astype('float32')+ 10*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "    return (data.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "\n",
    "class VOCSegDataset(gluon.data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_num, crop_size):\n",
    "        self.crop_size = crop_size\n",
    "        self.data, self.label = read_images(dataset_num=dataset_num)\n",
    "        self.data[:] = [normalize_image(im) for im in self.data]\n",
    "#         for i in range(len(self.data)):\n",
    "#             tmp = image_crop(self.data[i], self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "#             self.data[i].reshape(tmp.shape)\n",
    "#             self.data[i] = tmp.transpose((2,0,1))\n",
    "#             tmp = image_crop(self.label_image[i], self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "#             self.label_image[i].reshape(tmp.shape)\n",
    "#             self.label_image[i] = tmp.transpose((2,0,1))\n",
    "#         print('Read '+str(len(self.data))+' examples')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         data,label = image_crop(self.data[idx],self.label[idx],self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "        data = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "#         aug1 = image.HorizontalFlipAug(1)\n",
    "# #         aug2 = image.BrightnessJitterAug(1)\n",
    "# #         aug3 = image.ContrastJitterAug(1)\n",
    "#         if random.random() > 0.5:\n",
    "#         print(data.shape)\n",
    "#         data =  nd.flip(data, axis=0)\n",
    "#         label = nd.flip(label,0)\n",
    "#         data = aug2(data)\n",
    "#         data = aug3(data)\n",
    "            \n",
    "        return data.transpose((2,0,1)), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (64, 64)\n",
    "voc_train = VOCSegDataset(0, input_shape)\n",
    "voc_test1 = VOCSegDataset(1, input_shape)\n",
    "# voc_test2 = VOCSegDataset(2, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 64, 64)\n",
      "(8, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "train_data = gluon.data.DataLoader(\n",
    "    voc_train, batch_size, shuffle=True,last_batch='discard')\n",
    "test_data = gluon.data.DataLoader(\n",
    "    voc_test1, batch_size,last_batch='discard')\n",
    "\n",
    "for data, label in train_data:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (1, 3, 64, 64)\n",
      "After conv: (1, 10, 32, 32)\n",
      "After transposed conv (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "\n",
    "conv = nn.Conv2D(10, kernel_size=4, padding=1, strides=2)\n",
    "conv_trans = nn.Conv2DTranspose(3, kernel_size=4, padding=1, strides=2)\n",
    "\n",
    "conv.initialize()\n",
    "conv_trans.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(1,3,64,64))\n",
    "y = conv(x)\n",
    "print('Input:', x.shape)\n",
    "print('After conv:', y.shape)\n",
    "print('After transposed conv', conv_trans(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.model_zoo import vision as models\n",
    "pretrained_net = models.resnet50_v2(pretrained=True)\n",
    "\n",
    "# (pretrained_net.features[-4:], pretrained_net.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = nn.HybridSequential()\n",
    "for layer in pretrained_net.features[:-2]:\n",
    "    net.add(layer)\n",
    "\n",
    "# x = nd.random.uniform(shape=(1,3,*input_shape))\n",
    "# print('Input:', x.shape)\n",
    "# print('Output:', net(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridSequential(\n",
      "  (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=True, use_global_stats=False, in_channels=3)\n",
      "  (1): Conv2D(3 -> 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "  (3): Activation(relu)\n",
      "  (4): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(1, 1), ceil_mode=False)\n",
      "  (5): HybridSequential(\n",
      "    (0): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv1): Conv2D(64 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (downsample): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv1): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv1): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (6): HybridSequential(\n",
      "    (0): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv1): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (downsample): Conv2D(256 -> 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "    (1): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (7): HybridSequential(\n",
      "    (0): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv1): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (downsample): Conv2D(512 -> 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "    (1): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (8): HybridSequential(\n",
      "    (0): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (conv1): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (downsample): Conv2D(1024 -> 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "    (1): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "      (conv1): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): BottleneckV2(\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "      (conv1): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (9): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "  (10): Activation(relu)\n",
      "  (11): Conv2D(None -> 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (12): Conv2DTranspose(2 -> 0, kernel_size=(64, 64), stride=(32, 32), padding=(16, 16))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(classes)\n",
    "\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Conv2D(2, kernel_size=1),\n",
    "        nn.Conv2DTranspose(2, kernel_size=64, padding=16,strides=32)\n",
    "    )\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros(\n",
    "        (in_channels, out_channels, kernel_size, kernel_size),\n",
    "        dtype='float32')\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return nd.array(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# x = train_images[0]\n",
    "# print('Input', x.shape)\n",
    "# x = x.astype('float32').transpose((2,0,1)).expand_dims(axis=0)/255\n",
    "\n",
    "# conv_trans = nn.Conv2DTranspose(\n",
    "#     3, in_channels=3, kernel_size=8, padding=2, strides=4)\n",
    "# conv_trans.initialize()\n",
    "# conv_trans(x)\n",
    "# conv_trans.weight.set_data(bilinear_kernel(3, 3, 8))\n",
    "\n",
    "\n",
    "# y = conv_trans(x)\n",
    "# y = y[0].clip(0,1).transpose((1,2,0))\n",
    "# print('Output', y.shape)\n",
    "\n",
    "# plt.imshow(y.asnumpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "\n",
    "conv_trans = net[-1]\n",
    "conv_trans.initialize(init=init.Zero())\n",
    "net[-2].initialize(init=init.Xavier())\n",
    "\n",
    "x = nd.zeros((batch_size, 3, *input_shape))\n",
    "net(x)\n",
    "\n",
    "shape = conv_trans.weight.data().shape\n",
    "conv_trans.weight.set_data(bilinear_kernel(*shape[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss(axis=1)\n",
    "# loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "\n",
    "ctx = utils.try_all_gpus()\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        'NAG', {'learning_rate': 0.02, 'wd':1e-3})\n",
    "\n",
    "utils.train(train_data, test_data, net, loss,\n",
    "            trainer, ctx, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "def predict(im):\n",
    "#     mx.random.seed(np.random.randint(1, 1000))\n",
    "#     noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "#     data = ((im.astype('float32')+ 5*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "    data = normalize_image(im)\n",
    "#     data = (im.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "    data = data.transpose((2,0,1)).expand_dims(axis=0)\n",
    "    yhat = net(data.as_in_context(ctx[0]))\n",
    "    pred = nd.argmax(yhat, axis=1)\n",
    "    return pred.reshape((pred.shape[1], pred.shape[2]))\n",
    "\n",
    "def label2image(pred):\n",
    "    x = pred.astype('int32').asnumpy()\n",
    "    cm = nd.array(colormap).astype('uint8')\n",
    "    return nd.array(cm[x,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images,test_labels = read_images(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_acc(result, label, index):\n",
    "    if(len(np.where(result.asnumpy()>0)[1]) ==0 or len(np.where(label.asnumpy()>0)[1]) ==0):\n",
    "        return False,False,False,False\n",
    "#     result_maxx = np.max(np.where(result.asnumpy()>0)[1])\n",
    "#     result_minx = np.min(np.where(result.asnumpy()>0)[1])\n",
    "#     result_maxy = np.max(np.where(result.asnumpy()>0)[0])\n",
    "#     result_miny = np.min(np.where(result.asnumpy()>0)[0])\n",
    "\n",
    "#     result_centerx = int((result_maxx + result_minx)/2)\n",
    "#     result_centery = int((result_maxy + result_miny)/2)\n",
    "    txt_filename1 = txt_root + '/400_junior' + \"/%03d.txt\" % index\n",
    "    txt_filename2 = txt_root + '/400_predict_average' + \"/%03d.txt\" % index\n",
    "\n",
    "    with open(txt_filename1, 'r') as f:\n",
    "        txts = f.read().split()\n",
    "    with open(txt_filename2, 'r') as f:\n",
    "        txts1 = f.read().split()\n",
    "    x = int(txts[landmark_index].split(',')[0])- int(txts1[landmark_index].split(',')[0]) + 32\n",
    "    y = int(txts[landmark_index].split(',')[1])- int(txts1[landmark_index].split(',')[1]) + 32\n",
    "    \n",
    "    result_avgx = np.average(np.where(result.asnumpy()>0)[1])\n",
    "    result_avgy = np.average(np.where(result.asnumpy()>0)[0])\n",
    "\n",
    "#     label_maxx = np.max(np.where(label.asnumpy()>0)[1])\n",
    "#     label_minx = np.min(np.where(label.asnumpy()>0)[1])\n",
    "#     label_maxy = np.max(np.where(label.asnumpy()>0)[0])\n",
    "#     label_miny = np.min(np.where(label.asnumpy()>0)[0])\n",
    "    \n",
    "#     label_centerx = int((label_maxx + label_minx)/2)\n",
    "#     label_centery = int((label_maxy + label_miny)/2)\n",
    "    \n",
    "#     lable_avgx = np.average(np.where(label.asnumpy()>0)[1])\n",
    "#     lable_avgy = np.average(np.where(label.asnumpy()>0)[0])\n",
    "    \n",
    "#     d1 = pow((result_centerx - label_centerx),2) + pow((result_centery - label_centery),2)\n",
    "    d2 = pow((result_avgx - x),2) + pow((result_avgy - y),2)\n",
    "#     print(\"============================\")\n",
    "#     print(np.where(result.asnumpy()>0))\n",
    "#     print(result_centerx,label_centerx)\n",
    "#     print(result_centery,label_centery)\n",
    "#     print(d1,d2)\n",
    "    return (d2 < 400, d2 < 625, d2 < 900, d2 < 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6333333333333333    0.8466666666666667    0.9733333333333334    0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "n = len(test_images)\n",
    "# n = 10\n",
    "imgs = []\n",
    "acc1 = 0\n",
    "acc2 = 0\n",
    "acc3 = 0\n",
    "acc4 = 0\n",
    "\n",
    "# print(test_images[0])\n",
    "for i in range(n):\n",
    "    x = test_images[i]\n",
    "#     print(x.shape)\n",
    "#     start = time()\n",
    "    result = predict(x)\n",
    "    f1,f2,f3,f4 = evaluate_acc(result,test_labels[i],i+151)\n",
    "    acc1 += int(f1)\n",
    "    acc2 += int(f2)\n",
    "    acc3 += int(f3)\n",
    "    acc4 += int(f4)\n",
    "\n",
    "\n",
    "#     print(type(np.where(result.asnumpy()>0)[0]))\n",
    "#     print(np.where(test_labels[i].asnumpy()>0))\n",
    "    pred = label2image(predict(x))\n",
    "    imgs += [x, pred, label2image(test_labels[i])]\n",
    "print(acc1/n,\"  \", acc2/n,\"  \", acc3/n,\"  \", acc4/n)\n",
    "# utils.show_images(imgs, nrows=n, ncols=3, figsize=(6,20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_images,test_labels = read_images(18,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n = 10\n",
    "# imgs = []\n",
    "# for i in range(n):\n",
    "#     x = test_images[i]\n",
    "#     imgs += [x, label2image(test_labels[i]), label2image(test_labels[i])]\n",
    "# # \n",
    "# utils.show_images(imgs, nrows=n, ncols=3, figsize=(6,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
