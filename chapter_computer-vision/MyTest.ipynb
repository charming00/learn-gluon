{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mxnet import nd\n",
    "classes = ['background','p1','p2','p3','p4',\n",
    "           'p5','p6','p7','p8','p9','p10',\n",
    "           'p11','p12','p13','p14','p15',\n",
    "           'p16','p17','p18','p19']\n",
    "# RGB color for each class\n",
    "colormap = [[0,0,0],[128,0,0],[0,128,0], [128,128,0], [0,0,128],\n",
    "            [128,0,128],[0,64,128],[128,128,128],[64,0,0],[192,0,0],\n",
    "            [64,128,0],[192,128,0],[64,0,128],[192,0,128],\n",
    "            [64,128,128],[192,128,128],[0,64,0],[128,64,0],\n",
    "            [0,192,0],[128,192,0]]\n",
    "\n",
    "min_coordinate = [[504,697],[1063,606],[948,888],[286,902],[1079,1191],[1053,1507],[1048,1661],\n",
    "                  [993,1729],[1025,1706],[415,1391],[1121,1355],[1138,1388],[1245,1294],\n",
    "                  [1212,1477],[1170,1152],[1114,1756],[635,1090],[1081,1100],[350,1006]]\n",
    "expand_size = 55\n",
    "landmark_index = 5\n",
    "# len(classes), len(colormap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import image\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from time import time\n",
    "\n",
    "data_root = '../data'\n",
    "image_root = data_root + '/CephalometricLandmark/CroppedImage'\n",
    "# image_root = data_root + '/CephalometricLandmark/ContrastImage1'\n",
    "txt_root = data_root + '/CephalometricLandmark/AnnotationsByMD'\n",
    "\n",
    "\n",
    "def read_images(dataset_num=0):\n",
    "    contrast_size = 0\n",
    "    if dataset_num == 0:\n",
    "        begin_index = 1\n",
    "        end_index = 151\n",
    "        contrast_size = 5\n",
    "    elif dataset_num == 1:\n",
    "        begin_index = 151\n",
    "        end_index = 301\n",
    "    else:\n",
    "        begin_index = 301\n",
    "        end_index = 401\n",
    "\n",
    "    data, label = [None] * (end_index - begin_index) * (contrast_size + 1), [None] * (end_index - begin_index) * (\n",
    "            contrast_size + 1)\n",
    "    #     expand_label =  [None] * (end_index - begin_index)\n",
    "    #     bounding_box = [[[2000,2000],[0,0],[0,0]] for i in range(19)]\n",
    "    index = 0\n",
    "    for contrast_index in range(contrast_size + 1):\n",
    "        image_root = data_root + '/CephalometricLandmark/ContrastImage' + str(contrast_index)\n",
    "        for i in range(begin_index, end_index):\n",
    "            image_filename = image_root + \"/%02d/%03d.bmp\" % (landmark_index + 1, i)\n",
    "            txt_filename1 = txt_root + '/400_senior' + \"/%03d.txt\" % i\n",
    "            #         txt_filename2 =  txt_root + '/400_junior' +\"/%03d.txt\" % i\n",
    "            # #         label_image[index] = nd.zeros_like(data[index])\n",
    "\n",
    "            with open(txt_filename1, 'r') as f:\n",
    "                txts = f.read().split()\n",
    "            x = int(txts[landmark_index].split(',')[0]) - min_coordinate[landmark_index][0]\n",
    "            y = int(txts[landmark_index].split(',')[1]) - min_coordinate[landmark_index][1]\n",
    "            #         label_image[index][y-expand_size:y+expand_size,x-expand_size:x+expand_size] = colormap[landmark_index+1]\n",
    "\n",
    "            minx = x - expand_size\n",
    "            maxx = x + expand_size\n",
    "            if minx < 0:\n",
    "                minx = 0\n",
    "            if maxx >= 640:\n",
    "                maxx = 639\n",
    "\n",
    "            miny = y - expand_size\n",
    "            maxy = y + expand_size\n",
    "            if miny < 0:\n",
    "                miny = 0\n",
    "            if maxy >= 640:\n",
    "                maxy = 639\n",
    "\n",
    "            data[index] = image.imread(image_filename)\n",
    "            label[index] = cropped_label = nd.zeros((data[index].shape[0], data[index].shape[1]))\n",
    "            label[index][miny:maxy, minx:maxx] = 1\n",
    "            index += 1\n",
    "    return data, label\n",
    "\n",
    "# train_images, train_label_images, train_labels,bounding_boxes= read_images(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imgs = [train_images[0],train_label_images[0]]\n",
    "# # print(bounding_boxes)\n",
    "# # print(type(train_images))\n",
    "# landmarkindex = 2\n",
    "# margin_size = 100\n",
    "# for i in range(19):\n",
    "# #     imgs += [train_images[i][900:1100,800:1000],train_labels[i][990:1050,800:860]]\n",
    "# #     x = train_labels[i][1][0]\n",
    "# #     y = train_labels[i][1][1]\n",
    "# #     size = 40\n",
    "# #     imgs += [train_images[i][y-size:y+size,x-size:x+size],train_label_images[i][y-size:y+size,x-size:x+size]]\n",
    "    \n",
    "#     minx = bounding_boxes[0][0]\n",
    "#     miny = bounding_boxes[0][1]\n",
    "#     maxx = bounding_boxes[1][0]\n",
    "#     maxy = bounding_boxes[1][1]\n",
    "\n",
    "#     imgs += [train_images[i][miny-margin_size:maxy+margin_size,minx-margin_size:maxx+margin_size],train_label_images[i][miny-margin_size:maxy+margin_size,minx-margin_size:maxx+margin_size]]\n",
    "# # print(train_labels[0][981:1001,819:839])\n",
    "# utils.show_images(imgs, nrows=19, ncols=2,figsize=(12,160))\n",
    "# [im.shape for im in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# imgs = []\n",
    "# landmark_index = 0\n",
    "# for i in range(10):\n",
    "#     crop_image = image_crop(train_images[i],bounding_boxes[0],bounding_boxes[1])\n",
    "#     crop_label = image_crop(train_label_images[i],bounding_boxes[0],bounding_boxes[1])\n",
    "#     imgs += [crop_image,crop_label]\n",
    "# utils.show_images(imgs, nrows=10, ncols=2,figsize=(12,160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "import random\n",
    "\n",
    "rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def normalize_image(data):\n",
    "    return (data.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "\n",
    "class VOCSegDataset(gluon.data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_num, crop_size):\n",
    "        self.crop_size = crop_size\n",
    "        self.data, self.label = read_images(dataset_num=dataset_num)\n",
    "        self.data[:] = [normalize_image(im) for im in self.data]\n",
    "#         for i in range(len(self.data)):\n",
    "#             tmp = image_crop(self.data[i], self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "#             self.data[i].reshape(tmp.shape)\n",
    "#             self.data[i] = tmp.transpose((2,0,1))\n",
    "#             tmp = image_crop(self.label_image[i], self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "#             self.label_image[i].reshape(tmp.shape)\n",
    "#             self.label_image[i] = tmp.transpose((2,0,1))\n",
    "#         print('Read '+str(len(self.data))+' examples')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         data,label = image_crop(self.data[idx],self.label[idx],self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "        data = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        aug1 = image.HorizontalFlipAug(1)\n",
    "#         aug2 = image.BrightnessJitterAug(1)\n",
    "#         aug3 = image.ContrastJitterAug(1)\n",
    "        if random.random() > 0.5:\n",
    "            data = aug1(data)\n",
    "            label = nd.flip(label,1)\n",
    "#         data = aug2(data)\n",
    "#         data = aug3(data)\n",
    "            \n",
    "        return data.transpose((2,0,1)), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (640, 640)\n",
    "voc_train = VOCSegDataset(0, input_shape)\n",
    "voc_test1 = VOCSegDataset(1, input_shape)\n",
    "# voc_test2 = VOCSegDataset(2, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3, 640, 640)\n",
      "(16, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_data = gluon.data.DataLoader(\n",
    "    voc_train, batch_size, shuffle=True,last_batch='discard')\n",
    "test_data = gluon.data.DataLoader(\n",
    "    voc_test1, batch_size,last_batch='discard')\n",
    "\n",
    "for data, label in train_data:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "conv = nn.Conv2D(10, kernel_size=4, padding=1, strides=2)\n",
    "conv_trans = nn.Conv2DTranspose(3, kernel_size=4, padding=1, strides=2)\n",
    "\n",
    "conv.initialize()\n",
    "conv_trans.initialize()\n",
    "\n",
    "# x = nd.random.uniform(shape=(1,3,64,64))\n",
    "# y = conv(x)\n",
    "# print('Input:', x.shape)\n",
    "# print('After conv:', y.shape)\n",
    "# print('After transposed conv', conv_trans(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.model_zoo import vision as models\n",
    "pretrained_net = models.resnet18_v2(pretrained=True)\n",
    "\n",
    "# (pretrained_net.features[-4:], pretrained_net.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = nn.HybridSequential()\n",
    "for layer in pretrained_net.features[:-2]:\n",
    "    net.add(layer)\n",
    "\n",
    "# x = nd.random.uniform(shape=(1,3,*input_shape))\n",
    "# print('Input:', x.shape)\n",
    "# print('Output:', net(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(classes)\n",
    "\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Conv2D(2, kernel_size=1),\n",
    "        nn.Conv2DTranspose(2, kernel_size=64, padding=16,strides=32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros(\n",
    "        (in_channels, out_channels, kernel_size, kernel_size),\n",
    "        dtype='float32')\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return nd.array(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# x = train_images[0]\n",
    "# print('Input', x.shape)\n",
    "# x = x.astype('float32').transpose((2,0,1)).expand_dims(axis=0)/255\n",
    "\n",
    "# conv_trans = nn.Conv2DTranspose(\n",
    "#     3, in_channels=3, kernel_size=8, padding=2, strides=4)\n",
    "# conv_trans.initialize()\n",
    "# conv_trans(x)\n",
    "# conv_trans.weight.set_data(bilinear_kernel(3, 3, 8))\n",
    "\n",
    "\n",
    "# y = conv_trans(x)\n",
    "# y = y[0].clip(0,1).transpose((1,2,0))\n",
    "# print('Output', y.shape)\n",
    "\n",
    "# plt.imshow(y.asnumpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "\n",
    "conv_trans = net[-1]\n",
    "conv_trans.initialize(init=init.Zero())\n",
    "net[-2].initialize(init=init.Xavier())\n",
    "\n",
    "x = nd.zeros((batch_size, 3, *input_shape))\n",
    "net(x)\n",
    "\n",
    "shape = conv_trans.weight.data().shape\n",
    "conv_trans.weight.set_data(bilinear_kernel(*shape[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.078, Train acc 0.98, Test acc 0.98, Time 48.0 sec\n",
      "Epoch 1. Loss: 0.032, Train acc 0.99, Test acc 0.99, Time 38.7 sec\n",
      "Epoch 2. Loss: 0.026, Train acc 0.99, Test acc 0.99, Time 38.3 sec\n",
      "Epoch 3. Loss: 0.023, Train acc 0.99, Test acc 0.99, Time 38.5 sec\n",
      "Epoch 4. Loss: 0.020, Train acc 0.99, Test acc 0.99, Time 38.0 sec\n",
      "Epoch 5. Loss: 0.018, Train acc 0.99, Test acc 0.99, Time 38.0 sec\n",
      "Epoch 6. Loss: 0.017, Train acc 0.99, Test acc 0.99, Time 38.1 sec\n",
      "Epoch 7. Loss: 0.016, Train acc 0.99, Test acc 0.99, Time 37.6 sec\n",
      "Epoch 8. Loss: 0.015, Train acc 0.99, Test acc 0.99, Time 38.5 sec\n",
      "Epoch 9. Loss: 0.014, Train acc 0.99, Test acc 0.99, Time 38.1 sec\n",
      "Epoch 10. Loss: 0.013, Train acc 0.99, Test acc 0.99, Time 38.0 sec\n",
      "Epoch 11. Loss: 0.013, Train acc 0.99, Test acc 0.99, Time 38.4 sec\n",
      "Epoch 12. Loss: 0.012, Train acc 0.99, Test acc 0.99, Time 38.4 sec\n",
      "Epoch 13. Loss: 0.012, Train acc 0.99, Test acc 0.99, Time 38.1 sec\n",
      "Epoch 14. Loss: 0.011, Train acc 1.00, Test acc 0.99, Time 38.2 sec\n",
      "Epoch 15. Loss: 0.011, Train acc 1.00, Test acc 0.99, Time 38.4 sec\n",
      "Epoch 16. Loss: 0.011, Train acc 1.00, Test acc 0.99, Time 38.1 sec\n",
      "Epoch 17. Loss: 0.010, Train acc 1.00, Test acc 0.99, Time 38.6 sec\n",
      "Epoch 18. Loss: 0.010, Train acc 1.00, Test acc 0.99, Time 38.2 sec\n",
      "Epoch 19. Loss: 0.010, Train acc 1.00, Test acc 0.99, Time 38.7 sec\n",
      "Epoch 20. Loss: 0.009, Train acc 1.00, Test acc 0.99, Time 37.6 sec\n",
      "Epoch 21. Loss: 0.009, Train acc 1.00, Test acc 0.99, Time 38.0 sec\n",
      "Epoch 22. Loss: 0.009, Train acc 1.00, Test acc 0.99, Time 38.3 sec\n",
      "Epoch 23. Loss: 0.009, Train acc 1.00, Test acc 0.99, Time 38.9 sec\n",
      "Epoch 24. Loss: 0.009, Train acc 1.00, Test acc 0.99, Time 38.3 sec\n",
      "Epoch 25. Loss: 0.009, Train acc 1.00, Test acc 0.99, Time 38.0 sec\n",
      "Epoch 26. Loss: 0.008, Train acc 1.00, Test acc 0.99, Time 38.3 sec\n",
      "Epoch 27. Loss: 0.008, Train acc 1.00, Test acc 0.99, Time 38.3 sec\n",
      "Epoch 28. Loss: 0.008, Train acc 1.00, Test acc 0.99, Time 38.2 sec\n",
      "Epoch 29. Loss: 0.008, Train acc 1.00, Test acc 0.99, Time 38.0 sec\n",
      "Epoch 30. Loss: 0.008, Train acc 1.00, Test acc 0.99, Time 38.6 sec\n",
      "Epoch 31. Loss: 0.008, Train acc 1.00, Test acc 0.99, Time 38.3 sec\n",
      "Epoch 32. Loss: 0.007, Train acc 1.00, Test acc 0.99, Time 38.0 sec\n",
      "Epoch 33. Loss: 0.007, Train acc 1.00, Test acc 0.99, Time 38.4 sec\n",
      "Epoch 34. Loss: 0.007, Train acc 1.00, Test acc 0.99, Time 38.1 sec\n",
      "Epoch 35. Loss: 0.007, Train acc 1.00, Test acc 0.99, Time 38.5 sec\n",
      "Epoch 36. Loss: 0.007, Train acc 1.00, Test acc 0.99, Time 38.2 sec\n",
      "Epoch 37. Loss: 0.007, Train acc 1.00, Test acc 0.99, Time 38.4 sec\n",
      "Epoch 38. Loss: 0.007, Train acc 1.00, Test acc 0.99, Time 38.7 sec\n",
      "Epoch 39. Loss: 0.007, Train acc 1.00, Test acc 0.99, Time 38.0 sec\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss(axis=1)\n",
    "\n",
    "ctx = utils.try_all_gpus()\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        'sgd', {'learning_rate': .1, 'wd':1e-3})\n",
    "\n",
    "utils.train(train_data, test_data, net, loss,\n",
    "            trainer, ctx, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "def predict(im):\n",
    "    data = normalize_image(im)\n",
    "    data = data.transpose((2,0,1)).expand_dims(axis=0)\n",
    "    yhat = net(data.as_in_context(ctx[0]))\n",
    "    pred = nd.argmax(yhat, axis=1)\n",
    "    return pred.reshape((pred.shape[1], pred.shape[2]))\n",
    "\n",
    "def label2image(pred):\n",
    "    x = pred.astype('int32').asnumpy()\n",
    "    cm = nd.array(colormap).astype('uint8')\n",
    "    return nd.array(cm[x,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images,test_labels = read_images(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_acc(result, label):\n",
    "    if(len(np.where(result.asnumpy()>0)[1]) ==0):\n",
    "        return False,False,False,False,False,False,False,False\n",
    "    result_maxx = np.max(np.where(result.asnumpy()>0)[1])\n",
    "    result_minx = np.min(np.where(result.asnumpy()>0)[1])\n",
    "    result_maxy = np.max(np.where(result.asnumpy()>0)[0])\n",
    "    result_miny = np.min(np.where(result.asnumpy()>0)[0])\n",
    "\n",
    "    result_centerx = int((result_maxx + result_minx)/2)\n",
    "    result_centery = int((result_maxy + result_miny)/2)\n",
    "    \n",
    "    result_avgx = np.average(np.where(result.asnumpy()>0)[1])\n",
    "    result_avgy = np.average(np.where(result.asnumpy()>0)[0])\n",
    "\n",
    "    label_maxx = np.max(np.where(label.asnumpy()>0)[1])\n",
    "    label_minx = np.min(np.where(label.asnumpy()>0)[1])\n",
    "    label_maxy = np.max(np.where(label.asnumpy()>0)[0])\n",
    "    label_miny = np.min(np.where(label.asnumpy()>0)[0])\n",
    "    \n",
    "    label_centerx = int((label_maxx + label_minx)/2)\n",
    "    label_centery = int((label_maxy + label_miny)/2)\n",
    "    \n",
    "    lable_avgx = np.average(np.where(label.asnumpy()>0)[1])\n",
    "    lable_avgy = np.average(np.where(label.asnumpy()>0)[0])\n",
    "    \n",
    "    d1 = pow((result_centerx - label_centerx),2) + pow((result_centery - label_centery),2)\n",
    "    d2 = pow((result_avgx - label_centerx),2) + pow((result_avgy - label_centery),2)\n",
    "#     print(\"============================\")\n",
    "#     print(np.where(result.asnumpy()>0))\n",
    "#     print(result_centerx,label_centerx)\n",
    "#     print(result_centery,label_centery)\n",
    "#     print(d1,d2)\n",
    "    return (d1 < 400, d2 < 400, d1 < 625, d2 < 625, d1 < 900, d2 < 900, d1 < 1600, d2 < 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06    0.04    0.08    0.07    0.11    0.14    0.28    0.28\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "imgs = []\n",
    "acc1 = 0\n",
    "acc2 = 0\n",
    "acc3 = 0\n",
    "acc4 = 0\n",
    "acc5 = 0\n",
    "acc6 = 0\n",
    "acc7 = 0\n",
    "acc8 = 0\n",
    "for i in range(n):\n",
    "    x = test_images[i]\n",
    "#     print(x.shape)\n",
    "    start = time()\n",
    "    result = predict(x)\n",
    "    f1,f2,f3,f4,f5,f6,f7,f8 = evaluate_acc(result,test_labels[i])\n",
    "    acc1 += int(f1)\n",
    "    acc2 += int(f2)\n",
    "    acc3 += int(f3)\n",
    "    acc4 += int(f4)\n",
    "    acc5 += int(f5)\n",
    "    acc6 += int(f6)\n",
    "    acc7 += int(f7)\n",
    "    acc8 += int(f8)\n",
    "\n",
    "#     print(type(np.where(result.asnumpy()>0)[0]))\n",
    "#     print(np.where(test_labels[i].asnumpy()>0))\n",
    "    pred = label2image(predict(x))\n",
    "    imgs += [x, pred, label2image(test_labels[i])]\n",
    "print(acc1/n,\"  \", acc2/n,\"  \", acc3/n,\"  \", acc4/n,\"  \", acc5/n,\"  \", acc6/n,\"  \", acc7/n,\"  \", acc8/n)\n",
    "# utils.show_images(imgs, nrows=n, ncols=3, figsize=(6,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_images,test_labels = read_images(18,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n = 10\n",
    "# imgs = []\n",
    "# for i in range(n):\n",
    "#     x = test_images[i]\n",
    "#     imgs += [x, label2image(test_labels[i]), label2image(test_labels[i])]\n",
    "# # \n",
    "# utils.show_images(imgs, nrows=n, ncols=3, figsize=(6,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
