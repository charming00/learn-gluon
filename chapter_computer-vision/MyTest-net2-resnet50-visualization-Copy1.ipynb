{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from mxnet import image\n",
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn,Block\n",
    "from mxnet import init\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from time import time\n",
    "classes = ['background','p1','p2','p3','p4',\n",
    "           'p5','p6','p7','p8','p9','p10',\n",
    "           'p11','p12','p13','p14','p15',\n",
    "           'p16','p17','p18','p19']\n",
    "# RGB color for each class\n",
    "colormap = [[0,0,0],[128,0,0],[0,128,0], [128,128,0], [0,0,128],\n",
    "            [128,0,128],[0,64,128],[128,128,128],[64,0,0],[192,0,0],\n",
    "            [64,128,0],[192,128,0],[64,0,128],[192,0,128],\n",
    "            [64,128,128],[192,128,128],[0,64,0],[128,64,0],\n",
    "            [0,192,0],[128,192,0]]\n",
    "\n",
    "min_coordinate = [[504,697],[1063,606],[948,888],[286,902],[1079,1191],[1053,1507],[1048,1661],\n",
    "                  [993,1729],[1025,1706],[415,1391],[1121,1355],[1138,1388],[1245,1294],\n",
    "                  [1212,1477],[1170,1152],[1114,1756],[635,1090],[1081,1100],[350,1006]]\n",
    "expand_size = 16\n",
    "\n",
    "landmark_index = 9\n",
    "\n",
    "# len(classes), len(colormap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import image\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from time import time\n",
    "\n",
    "data_root = '../data'\n",
    "image_root = data_root + '/CephalometricLandmark/CroppedImage'\n",
    "# image_root = data_root + '/CephalometricLandmark/ContrastImage1'\n",
    "txt_root = data_root + '/CephalometricLandmark/AnnotationsByMD'\n",
    "model_params_root = data_root + '/CephalometricLandmark/model_params'\n",
    "\n",
    "def read_images(dataset_num=0):\n",
    "    contrast_size = 0\n",
    "    if dataset_num == 0:\n",
    "        begin_index = 1\n",
    "        end_index = 151\n",
    "        contrast_size = 0\n",
    "    elif dataset_num == 1:\n",
    "        begin_index = 151\n",
    "        end_index = 301\n",
    "    else:\n",
    "        begin_index = 301\n",
    "        end_index = 401\n",
    "\n",
    "    data, label = [None] * (end_index - begin_index) * (contrast_size + 1), [None] * (end_index - begin_index) * (\n",
    "            contrast_size + 1)\n",
    "    #     expand_label =  [None] * (end_index - begin_index)\n",
    "    #     bounding_box = [[[2000,2000],[0,0],[0,0]] for i in range(19)]\n",
    "    index = 0\n",
    "    for contrast_index in range(contrast_size + 1):\n",
    "#         image_root = data_root + '/CephalometricLandmark/ContrastImage' + str(contrast_index)\n",
    "#         image_root = data_root + '/CephalometricLandmark/GaussianNoise' + str(contrast_index)\n",
    "        for i in range(begin_index, end_index):\n",
    "            image_filename = image_root + \"/%02d/%03d.bmp\" % (landmark_index + 1, i)\n",
    "            txt_filename1 = txt_root + '/400_junior' + \"/%03d.txt\" % i\n",
    "            txt_filename2 = txt_root + '/400_predict_average' + \"/%03d.txt\" % i\n",
    "            # #         label_image[index] = nd.zeros_like(data[index])\n",
    "\n",
    "            with open(txt_filename1, 'r') as f:\n",
    "                txts = f.read().split()\n",
    "            with open(txt_filename2, 'r') as f:\n",
    "                txts1 = f.read().split()\n",
    "#             x = int((int(txts[landmark_index].split(',')[0]) + int(txts1[landmark_index].split(',')[0]))/2) - min_coordinate[landmark_index][0]\n",
    "#             y = int((int(txts[landmark_index].split(',')[1]) + int(txts1[landmark_index].split(',')[1]))/2) - min_coordinate[landmark_index][1]\n",
    "            #         label_image[index][y-expand_size:y+expand_size,x-expand_size:x+expand_size] = colormap[landmark_index+1]\n",
    "            rand_numx = 0\n",
    "            rand_numy = 0\n",
    "            random_range = 20\n",
    "            if dataset_num == 0:\n",
    "                rand_numx = random.randint(-random_range, random_range)\n",
    "                rand_numy = random.randint(-random_range, random_range)\n",
    "            \n",
    "            \n",
    "            crop_x = int(txts1[landmark_index].split(',')[0]) - min_coordinate[landmark_index][0] + rand_numx\n",
    "            crop_y = int(txts1[landmark_index].split(',')[1]) - min_coordinate[landmark_index][1] + rand_numy\n",
    "            crop_minx = crop_x - 32\n",
    "            if crop_minx < 0:\n",
    "                crop_minx = 0\n",
    "            if crop_minx + 64 > 640:\n",
    "                crop_minx = 640 - 64\n",
    "            \n",
    "            crop_miny = crop_y - 32\n",
    "            if crop_miny < 0:\n",
    "                crop_miny = 0\n",
    "            if crop_miny + 64 > 640:\n",
    "                crop_miny = 640 - 64\n",
    "            \n",
    "            x = int(txts[landmark_index].split(',')[0]) - min_coordinate[landmark_index][0] - crop_minx\n",
    "            y = int(txts[landmark_index].split(',')[1]) - min_coordinate[landmark_index][1] - crop_miny\n",
    "            print(x,y)\n",
    "                \n",
    "            minx = x - expand_size\n",
    "            maxx = x + expand_size\n",
    "            if minx < 0:\n",
    "                minx = 0\n",
    "            if minx >= 64:\n",
    "                minx = 63\n",
    "            if maxx < 0:\n",
    "                maxx = 0\n",
    "            if maxx >= 64:\n",
    "                maxx = 63\n",
    "\n",
    "            miny = y - expand_size\n",
    "            maxy = y + expand_size\n",
    "            if miny < 0:\n",
    "                miny = 0\n",
    "            if miny >= 64:\n",
    "                miny = 63\n",
    "            if maxy < 0:\n",
    "                maxy = 0\n",
    "            if maxy >= 64:\n",
    "                maxy = 63\n",
    "            data[index] = image.imread(image_filename)[crop_miny:crop_miny+64,crop_minx:crop_minx+64]\n",
    "            label[index] = nd.zeros((data[index].shape[0], data[index].shape[1]))\n",
    "#             print(label[index].shape)\n",
    "            print(miny,maxy,minx,maxx)\n",
    "            if miny != maxy and minx != maxx:\n",
    "                label[index][miny:maxy, minx:maxx] = 1\n",
    "#             label[index] = nd.flip(label[index],0)\n",
    "#             print(data[index].shape,label[index].shape)\n",
    "            index += 1\n",
    "            \n",
    "    return data, label\n",
    "\n",
    "# train_images, train_label_images, train_labels,bounding_boxes= read_images(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imgs = [train_images[0],train_label_images[0]]\n",
    "# # print(bounding_boxes)\n",
    "# # print(type(train_images))\n",
    "# landmarkindex = 2\n",
    "# margin_size = 100\n",
    "# for i in range(19):\n",
    "# #     imgs += [train_images[i][900:1100,800:1000],train_labels[i][990:1050,800:860]]\n",
    "# #     x = train_labels[i][1][0]\n",
    "# #     y = train_labels[i][1][1]\n",
    "# #     size = 40\n",
    "# #     imgs += [train_images[i][y-size:y+size,x-size:x+size],train_label_images[i][y-size:y+size,x-size:x+size]]\n",
    "    \n",
    "#     minx = bounding_boxes[0][0]\n",
    "#     miny = bounding_boxes[0][1]\n",
    "#     maxx = bounding_boxes[1][0]\n",
    "#     maxy = bounding_boxes[1][1]\n",
    "\n",
    "#     imgs += [train_images[i][miny-margin_size:maxy+margin_size,minx-margin_size:maxx+margin_size],train_label_images[i][miny-margin_size:maxy+margin_size,minx-margin_size:maxx+margin_size]]\n",
    "# # print(train_labels[0][981:1001,819:839])\n",
    "# utils.show_images(imgs, nrows=19, ncols=2,figsize=(12,160))\n",
    "# [im.shape for im in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# imgs = []\n",
    "# landmark_index = 0\n",
    "# for i in range(10):\n",
    "#     crop_image = image_crop(train_images[i],bounding_boxes[0],bounding_boxes[1])\n",
    "#     crop_label = image_crop(train_label_images[i],bounding_boxes[0],bounding_boxes[1])\n",
    "#     imgs += [crop_image,crop_label]\n",
    "# utils.show_images(imgs, nrows=10, ncols=2,figsize=(12,160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "import random\n",
    "\n",
    "rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def normalize_image(data):\n",
    "#     mx.random.seed(np.random.randint(1, 1000))\n",
    "#     noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "#     return ((data.astype('float32')+ 10*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "    return (data.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "\n",
    "class VOCSegDataset(gluon.data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_num, crop_size):\n",
    "        self.crop_size = crop_size\n",
    "        self.data, self.label = read_images(dataset_num=dataset_num)\n",
    "        self.data[:] = [normalize_image(im) for im in self.data]\n",
    "#         for i in range(len(self.data)):\n",
    "#             tmp = image_crop(self.data[i], self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "#             self.data[i].reshape(tmp.shape)\n",
    "#             self.data[i] = tmp.transpose((2,0,1))\n",
    "#             tmp = image_crop(self.label_image[i], self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "#             self.label_image[i].reshape(tmp.shape)\n",
    "#             self.label_image[i] = tmp.transpose((2,0,1))\n",
    "#         print('Read '+str(len(self.data))+' examples')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         data,label = image_crop(self.data[idx],self.label[idx],self.bounding_box[0], self.bounding_box[1],*self.crop_size)\n",
    "        data = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "#         aug1 = image.HorizontalFlipAug(1)\n",
    "# #         aug2 = image.BrightnessJitterAug(1)\n",
    "# #         aug3 = image.ContrastJitterAug(1)\n",
    "#         if random.random() > 0.5:\n",
    "#         print(data.shape)\n",
    "#         data =  nd.flip(data, axis=0)\n",
    "#         label = nd.flip(label,0)\n",
    "#         data = aug2(data)\n",
    "#         data = aug3(data)\n",
    "            \n",
    "        return data.transpose((2,0,1)), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 50\n",
      "34 63 31 63\n",
      "28 40\n",
      "24 56 12 44\n",
      "50 42\n",
      "26 58 34 63\n",
      "39 42\n",
      "26 58 23 55\n",
      "38 30\n",
      "14 46 22 54\n",
      "20 25\n",
      "9 41 4 36\n",
      "48 25\n",
      "9 41 32 63\n",
      "13 16\n",
      "0 32 0 29\n",
      "43 26\n",
      "10 42 27 59\n",
      "27 22\n",
      "6 38 11 43\n",
      "23 51\n",
      "35 63 7 39\n",
      "36 34\n",
      "18 50 20 52\n",
      "21 15\n",
      "0 31 5 37\n",
      "26 52\n",
      "36 63 10 42\n",
      "25 36\n",
      "20 52 9 41\n",
      "25 24\n",
      "8 40 9 41\n",
      "18 34\n",
      "18 50 2 34\n",
      "45 12\n",
      "0 28 29 61\n",
      "24 42\n",
      "26 58 8 40\n",
      "50 36\n",
      "20 52 34 63\n",
      "31 25\n",
      "9 41 15 47\n",
      "31 32\n",
      "16 48 15 47\n",
      "39 29\n",
      "13 45 23 55\n",
      "37 51\n",
      "35 63 21 53\n",
      "16 52\n",
      "36 63 0 32\n",
      "33 28\n",
      "12 44 17 49\n",
      "17 12\n",
      "0 28 1 33\n",
      "29 36\n",
      "20 52 13 45\n",
      "25 31\n",
      "15 47 9 41\n",
      "20 51\n",
      "35 63 4 36\n",
      "30 23\n",
      "7 39 14 46\n",
      "18 21\n",
      "5 37 2 34\n",
      "48 48\n",
      "32 63 32 63\n",
      "25 32\n",
      "16 48 9 41\n",
      "46 16\n",
      "0 32 30 62\n",
      "49 23\n",
      "7 39 33 63\n",
      "31 19\n",
      "3 35 15 47\n",
      "15 28\n",
      "12 44 0 31\n",
      "39 25\n",
      "9 41 23 55\n",
      "37 45\n",
      "29 61 21 53\n",
      "13 17\n",
      "1 33 0 29\n",
      "16 44\n",
      "28 60 0 32\n",
      "19 29\n",
      "13 45 3 35\n",
      "29 20\n",
      "4 36 13 45\n",
      "43 21\n",
      "5 37 27 59\n",
      "49 44\n",
      "28 60 33 63\n",
      "23 20\n",
      "4 36 7 39\n",
      "28 43\n",
      "27 59 12 44\n",
      "34 50\n",
      "34 63 18 50\n",
      "50 44\n",
      "28 60 34 63\n",
      "20 52\n",
      "36 63 4 36\n",
      "38 12\n",
      "0 28 22 54\n",
      "25 43\n",
      "27 59 9 41\n",
      "51 13\n",
      "0 29 35 63\n",
      "38 24\n",
      "8 40 22 54\n",
      "41 28\n",
      "12 44 25 57\n",
      "17 46\n",
      "30 62 1 33\n",
      "29 44\n",
      "28 60 13 45\n",
      "26 37\n",
      "21 53 10 42\n",
      "50 34\n",
      "18 50 34 63\n",
      "14 52\n",
      "36 63 0 30\n",
      "30 32\n",
      "16 48 14 46\n",
      "33 16\n",
      "0 32 17 49\n",
      "13 34\n",
      "18 50 0 29\n",
      "45 16\n",
      "0 32 29 61\n",
      "33 38\n",
      "22 54 17 49\n",
      "18 14\n",
      "0 30 2 34\n",
      "35 15\n",
      "0 31 19 51\n",
      "14 51\n",
      "35 63 0 30\n",
      "28 47\n",
      "31 63 12 44\n",
      "43 37\n",
      "21 53 27 59\n",
      "20 36\n",
      "20 52 4 36\n",
      "47 24\n",
      "8 40 31 63\n",
      "37 34\n",
      "18 50 21 53\n",
      "39 24\n",
      "8 40 23 55\n",
      "17 31\n",
      "15 47 1 33\n",
      "31 48\n",
      "32 63 15 47\n",
      "22 13\n",
      "0 29 6 38\n",
      "43 36\n",
      "20 52 27 59\n",
      "12 23\n",
      "7 39 0 28\n",
      "16 27\n",
      "11 43 0 32\n",
      "48 44\n",
      "28 60 32 63\n",
      "45 38\n",
      "22 54 29 61\n",
      "17 35\n",
      "19 51 1 33\n",
      "20 50\n",
      "34 63 4 36\n",
      "32 17\n",
      "1 33 16 48\n",
      "26 51\n",
      "35 63 10 42\n",
      "28 52\n",
      "36 63 12 44\n",
      "51 42\n",
      "26 58 35 63\n",
      "14 40\n",
      "24 56 0 30\n",
      "39 43\n",
      "27 59 23 55\n",
      "52 45\n",
      "29 61 36 63\n",
      "43 42\n",
      "26 58 27 59\n",
      "14 52\n",
      "36 63 0 30\n",
      "21 20\n",
      "4 36 5 37\n",
      "40 20\n",
      "4 36 24 56\n",
      "42 26\n",
      "10 42 26 58\n",
      "27 24\n",
      "8 40 11 43\n",
      "41 19\n",
      "3 35 25 57\n",
      "24 17\n",
      "1 33 8 40\n",
      "51 36\n",
      "20 52 35 63\n",
      "52 39\n",
      "23 55 36 63\n",
      "51 17\n",
      "1 33 35 63\n",
      "26 28\n",
      "12 44 10 42\n",
      "17 13\n",
      "0 29 1 33\n",
      "21 22\n",
      "6 38 5 37\n",
      "51 19\n",
      "3 35 35 63\n",
      "22 13\n",
      "0 29 6 38\n",
      "32 42\n",
      "26 58 16 48\n",
      "39 41\n",
      "25 57 23 55\n",
      "48 39\n",
      "23 55 32 63\n",
      "30 12\n",
      "0 28 14 46\n",
      "32 19\n",
      "3 35 16 48\n",
      "44 52\n",
      "36 63 28 60\n",
      "50 23\n",
      "7 39 34 63\n",
      "15 42\n",
      "26 58 0 31\n",
      "26 25\n",
      "9 41 10 42\n",
      "38 13\n",
      "0 29 22 54\n",
      "48 38\n",
      "22 54 32 63\n",
      "14 52\n",
      "36 63 0 30\n",
      "26 31\n",
      "15 47 10 42\n",
      "27 34\n",
      "18 50 11 43\n",
      "42 29\n",
      "13 45 26 58\n",
      "22 51\n",
      "35 63 6 38\n",
      "22 24\n",
      "8 40 6 38\n",
      "20 35\n",
      "19 51 4 36\n",
      "16 14\n",
      "0 30 0 32\n",
      "30 43\n",
      "27 59 14 46\n",
      "23 36\n",
      "20 52 7 39\n",
      "19 38\n",
      "22 54 3 35\n",
      "15 21\n",
      "5 37 0 31\n",
      "16 14\n",
      "0 30 0 32\n",
      "13 52\n",
      "36 63 0 29\n",
      "18 12\n",
      "0 28 2 34\n",
      "41 36\n",
      "20 52 25 57\n",
      "50 40\n",
      "24 56 34 63\n",
      "21 50\n",
      "34 63 5 37\n",
      "52 33\n",
      "17 49 36 63\n",
      "51 49\n",
      "33 63 35 63\n",
      "39 13\n",
      "0 29 23 55\n",
      "27 48\n",
      "32 63 11 43\n",
      "16 38\n",
      "22 54 0 32\n",
      "33 12\n",
      "0 28 17 49\n",
      "15 48\n",
      "32 63 0 31\n",
      "37 45\n",
      "29 61 21 53\n",
      "39 41\n",
      "25 57 23 55\n",
      "18 35\n",
      "19 51 2 34\n",
      "49 33\n",
      "17 49 33 63\n",
      "29 26\n",
      "10 42 13 45\n",
      "33 16\n",
      "0 32 17 49\n",
      "30 29\n",
      "13 45 14 46\n",
      "5 25\n",
      "9 41 0 21\n",
      "2 10\n",
      "0 26 0 18\n",
      "17 6\n",
      "0 22 1 33\n",
      "36 51\n",
      "35 63 20 52\n",
      "-13 -10\n",
      "0 6 0 3\n",
      "22 19\n",
      "3 35 6 38\n",
      "9 17\n",
      "1 33 0 25\n",
      "18 23\n",
      "7 39 2 34\n",
      "4 1\n",
      "0 17 0 20\n",
      "29 37\n",
      "21 53 13 45\n",
      "28 35\n",
      "19 51 12 44\n",
      "33 38\n",
      "22 54 17 49\n",
      "25 31\n",
      "15 47 9 41\n",
      "31 32\n",
      "16 48 15 47\n",
      "22 26\n",
      "10 42 6 38\n",
      "39 44\n",
      "28 60 23 55\n",
      "59 68\n",
      "52 63 43 63\n",
      "25 36\n",
      "20 52 9 41\n",
      "34 24\n",
      "8 40 18 50\n",
      "54 60\n",
      "44 63 38 63\n",
      "34 22\n",
      "6 38 18 50\n",
      "47 34\n",
      "18 50 31 63\n",
      "60 72\n",
      "56 63 44 63\n",
      "29 39\n",
      "23 55 13 45\n",
      "41 35\n",
      "19 51 25 57\n",
      "25 25\n",
      "9 41 9 41\n",
      "40 29\n",
      "13 45 24 56\n",
      "46 40\n",
      "24 56 30 62\n",
      "25 15\n",
      "0 31 9 41\n",
      "34 23\n",
      "7 39 18 50\n",
      "92 69\n",
      "53 63 63 63\n",
      "25 30\n",
      "14 46 9 41\n",
      "19 17\n",
      "1 33 3 35\n",
      "40 44\n",
      "28 60 24 56\n",
      "30 45\n",
      "29 61 14 46\n",
      "41 51\n",
      "35 63 25 57\n",
      "34 31\n",
      "15 47 18 50\n",
      "38 46\n",
      "30 62 22 54\n",
      "32 39\n",
      "23 55 16 48\n",
      "63 0\n",
      "0 16 47 63\n",
      "27 42\n",
      "26 58 11 43\n",
      "43 25\n",
      "9 41 27 59\n",
      "39 -43\n",
      "0 0 23 55\n",
      "23 17\n",
      "1 33 7 39\n",
      "46 33\n",
      "17 49 30 62\n",
      "45 39\n",
      "23 55 29 61\n",
      "42 50\n",
      "34 63 26 58\n",
      "2 27\n",
      "11 43 0 18\n",
      "18 31\n",
      "15 47 2 34\n",
      "31 27\n",
      "11 43 15 47\n",
      "24 23\n",
      "7 39 8 40\n",
      "33 53\n",
      "37 63 17 49\n",
      "18 30\n",
      "14 46 2 34\n",
      "21 -8\n",
      "0 8 5 37\n",
      "11 9\n",
      "0 25 0 27\n",
      "25 41\n",
      "25 57 9 41\n",
      "83 -21\n",
      "0 0 63 63\n",
      "32 17\n",
      "1 33 16 48\n",
      "46 39\n",
      "23 55 30 62\n",
      "27 21\n",
      "5 37 11 43\n",
      "49 59\n",
      "43 63 33 63\n",
      "45 38\n",
      "22 54 29 61\n",
      "24 41\n",
      "25 57 8 40\n",
      "49 30\n",
      "14 46 33 63\n",
      "37 36\n",
      "20 52 21 53\n",
      "30 29\n",
      "13 45 14 46\n",
      "12 34\n",
      "18 50 0 28\n",
      "42 61\n",
      "45 63 26 58\n",
      "27 34\n",
      "18 50 11 43\n",
      "42 15\n",
      "0 31 26 58\n",
      "42 43\n",
      "27 59 26 58\n",
      "41 15\n",
      "0 31 25 57\n",
      "26 39\n",
      "23 55 10 42\n",
      "53 22\n",
      "6 38 37 63\n",
      "42 9\n",
      "0 25 26 58\n",
      "50 54\n",
      "38 63 34 63\n",
      "60 18\n",
      "2 34 44 63\n",
      "71 82\n",
      "63 63 55 63\n",
      "56 33\n",
      "17 49 40 63\n",
      "46 41\n",
      "25 57 30 62\n",
      "21 15\n",
      "0 31 5 37\n",
      "32 70\n",
      "54 63 16 48\n",
      "43 56\n",
      "40 63 27 59\n",
      "19 47\n",
      "31 63 3 35\n",
      "36 29\n",
      "13 45 20 52\n",
      "39 22\n",
      "6 38 23 55\n",
      "28 36\n",
      "20 52 12 44\n",
      "33 32\n",
      "16 48 17 49\n",
      "25 40\n",
      "24 56 9 41\n",
      "29 25\n",
      "9 41 13 45\n",
      "28 38\n",
      "22 54 12 44\n",
      "69 40\n",
      "24 56 53 63\n",
      "41 51\n",
      "35 63 25 57\n",
      "39 33\n",
      "17 49 23 55\n",
      "41 43\n",
      "27 59 25 57\n",
      "21 22\n",
      "6 38 5 37\n",
      "33 38\n",
      "22 54 17 49\n",
      "27 21\n",
      "5 37 11 43\n",
      "34 24\n",
      "8 40 18 50\n",
      "22 21\n",
      "5 37 6 38\n",
      "33 58\n",
      "42 63 17 49\n",
      "40 42\n",
      "26 58 24 56\n",
      "28 29\n",
      "13 45 12 44\n",
      "33 21\n",
      "5 37 17 49\n",
      "24 30\n",
      "14 46 8 40\n",
      "44 33\n",
      "17 49 28 60\n",
      "29 37\n",
      "21 53 13 45\n",
      "28 8\n",
      "0 24 12 44\n",
      "48 33\n",
      "17 49 32 63\n",
      "40 42\n",
      "26 58 24 56\n",
      "42 54\n",
      "38 63 26 58\n",
      "52 52\n",
      "36 63 36 63\n",
      "46 29\n",
      "13 45 30 62\n",
      "32 23\n",
      "7 39 16 48\n",
      "42 37\n",
      "21 53 26 58\n",
      "23 27\n",
      "11 43 7 39\n",
      "88 83\n",
      "63 63 63 63\n",
      "41 52\n",
      "36 63 25 57\n",
      "45 46\n",
      "30 62 29 61\n",
      "64 70\n",
      "54 63 48 63\n",
      "24 15\n",
      "0 31 8 40\n",
      "38 36\n",
      "20 52 22 54\n",
      "36 -5\n",
      "0 11 20 52\n",
      "22 9\n",
      "0 25 6 38\n",
      "35 15\n",
      "0 31 19 51\n",
      "51 25\n",
      "9 41 35 63\n",
      "25 32\n",
      "16 48 9 41\n",
      "38 29\n",
      "13 45 22 54\n",
      "33 11\n",
      "0 27 17 49\n",
      "29 5\n",
      "0 21 13 45\n",
      "38 46\n",
      "30 62 22 54\n",
      "48 47\n",
      "31 63 32 63\n",
      "27 14\n",
      "0 30 11 43\n",
      "31 19\n",
      "3 35 15 47\n",
      "28 26\n",
      "10 42 12 44\n",
      "26 18\n",
      "2 34 10 42\n",
      "48 6\n",
      "0 22 32 63\n",
      "50 40\n",
      "24 56 34 63\n",
      "18 16\n",
      "0 32 2 34\n",
      "32 33\n",
      "17 49 16 48\n",
      "26 24\n",
      "8 40 10 42\n",
      "43 48\n",
      "32 63 27 59\n",
      "33 29\n",
      "13 45 17 49\n",
      "56 52\n",
      "36 63 40 63\n",
      "41 47\n",
      "31 63 25 57\n",
      "43 43\n",
      "27 59 27 59\n",
      "36 20\n",
      "4 36 20 52\n",
      "36 42\n",
      "26 58 20 52\n",
      "35 36\n",
      "20 52 19 51\n"
     ]
    }
   ],
   "source": [
    "input_shape = (64, 64)\n",
    "voc_train = VOCSegDataset(0, input_shape)\n",
    "voc_test1 = VOCSegDataset(1, input_shape)\n",
    "# voc_test2 = VOCSegDataset(2, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 64, 64)\n",
      "(8, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "train_data = gluon.data.DataLoader(\n",
    "    voc_train, batch_size, shuffle=True,last_batch='discard')\n",
    "test_data = gluon.data.DataLoader(\n",
    "    voc_test1, batch_size,last_batch='discard')\n",
    "\n",
    "for data, label in train_data:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (1, 3, 64, 64)\n",
      "After conv: (1, 10, 32, 32)\n",
      "After transposed conv (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "\n",
    "conv = nn.Conv2D(10, kernel_size=4, padding=1, strides=2)\n",
    "conv_trans = nn.Conv2DTranspose(3, kernel_size=4, padding=1, strides=2)\n",
    "\n",
    "conv.initialize()\n",
    "conv_trans.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(1,3,64,64))\n",
    "y = conv(x)\n",
    "print('Input:', x.shape)\n",
    "print('After conv:', y.shape)\n",
    "print('After transposed conv', conv_trans(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.model_zoo import vision as models\n",
    "pretrained_net = models.densenet121(pretrained=True)\n",
    "\n",
    "# (pretrained_net.features[-4:], pretrained_net.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (1, 3, 64, 64)\n",
      "Output: (1, 1024, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "net = nn.HybridSequential()\n",
    "for layer in pretrained_net.features[:-2]:\n",
    "    net.add(layer)\n",
    "\n",
    "x = nd.random.uniform(shape=(1,3,*input_shape))\n",
    "print('Input:', x.shape)\n",
    "print('Output:', net(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridSequential(\n",
      "  (0): Conv2D(3 -> 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "  (2): Activation(relu)\n",
      "  (3): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(1, 1), ceil_mode=False)\n",
      "  (4): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(64 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=96)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(96 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=160)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(160 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=192)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(192 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=224)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(224 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (5): HybridSequential(\n",
      "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "    (1): Activation(relu)\n",
      "    (2): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): AvgPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (6): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=160)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(160 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=192)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(192 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=224)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(224 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=288)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(288 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=320)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(320 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (7): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=352)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(352 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (8): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=384)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(384 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (9): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=416)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(416 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (10): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=448)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(448 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (11): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=480)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(480 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (7): HybridSequential(\n",
      "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (1): Activation(relu)\n",
      "    (2): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): AvgPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (8): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=288)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(288 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=320)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(320 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=352)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(352 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=384)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(384 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=416)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(416 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=448)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(448 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (7): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=480)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(480 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (8): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (9): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=544)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(544 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (10): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=576)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(576 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (11): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=608)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(608 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (12): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=640)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(640 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (13): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=672)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(672 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (14): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=704)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(704 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (15): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=736)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(736 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (16): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=768)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(768 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (17): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=800)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(800 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (18): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=832)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(832 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (19): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=864)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(864 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (20): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=896)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(896 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (21): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=928)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(928 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (22): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=960)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(960 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (23): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=992)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(992 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (9): HybridSequential(\n",
      "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "    (1): Activation(relu)\n",
      "    (2): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): AvgPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (10): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=544)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(544 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=576)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(576 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=608)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(608 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=640)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(640 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=672)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(672 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=704)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(704 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (7): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=736)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(736 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (8): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=768)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(768 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (9): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=800)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(800 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (10): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=832)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(832 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (11): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=864)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(864 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (12): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=896)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(896 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (13): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=928)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(928 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (14): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=960)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(960 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (15): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=992)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(992 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(128 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (11): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "  (12): Activation(relu)\n",
      "  (13): Conv2D(None -> 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (14): Conv2DTranspose(2 -> 0, kernel_size=(64, 64), stride=(32, 32), padding=(16, 16))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(classes)\n",
    "\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Conv2D(2, kernel_size=1),\n",
    "        nn.Conv2DTranspose(2, kernel_size=64, padding=16,strides=32)\n",
    "    )\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros(\n",
    "        (in_channels, out_channels, kernel_size, kernel_size),\n",
    "        dtype='float32')\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return nd.array(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# x = train_images[0]\n",
    "# print('Input', x.shape)\n",
    "# x = x.astype('float32').transpose((2,0,1)).expand_dims(axis=0)/255\n",
    "\n",
    "# conv_trans = nn.Conv2DTranspose(\n",
    "#     3, in_channels=3, kernel_size=8, padding=2, strides=4)\n",
    "# conv_trans.initialize()\n",
    "# conv_trans(x)\n",
    "# conv_trans.weight.set_data(bilinear_kernel(3, 3, 8))\n",
    "\n",
    "\n",
    "# y = conv_trans(x)\n",
    "# y = y[0].clip(0,1).transpose((1,2,0))\n",
    "# print('Output', y.shape)\n",
    "\n",
    "# plt.imshow(y.asnumpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "\n",
    "conv_trans = net[-1]\n",
    "conv_trans.initialize(init=init.Zero())\n",
    "net[-2].initialize(init=init.Xavier())\n",
    "\n",
    "x = nd.zeros((batch_size, 3, *input_shape))\n",
    "net(x)\n",
    "\n",
    "shape = conv_trans.weight.data().shape\n",
    "conv_trans.weight.set_data(bilinear_kernel(*shape[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss(axis=1)\n",
    "# loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "\n",
    "ctx = utils.try_all_gpus()\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        'SGD', {'learning_rate': 0.02, 'wd':1e-3})\n",
    "\n",
    "utils.train(train_data, test_data, net, loss,\n",
    "            trainer, ctx, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# net.save_params(model_params_root + \"/net2-mark10-resnet18-epochs100.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "def predict(im):\n",
    "#     mx.random.seed(np.random.randint(1, 1000))\n",
    "#     noise = mx.nd.random.normal(0, 1, shape=(640, 640, 1), dtype=np.float32)\n",
    "#     data = ((im.astype('float32')+ 5*noise).clip(0, 255) / 255 - rgb_mean) / rgb_std\n",
    "    data = normalize_image(im)\n",
    "#     data = (im.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "    data = data.transpose((2,0,1)).expand_dims(axis=0)\n",
    "    yhat = net(data.as_in_context(ctx[0]))\n",
    "    pred = nd.argmax(yhat, axis=1)\n",
    "    return pred.reshape((pred.shape[1], pred.shape[2]))\n",
    "\n",
    "def label2image(pred):\n",
    "    x = pred.astype('int32').asnumpy()\n",
    "    cm = nd.array(colormap).astype('uint8')\n",
    "    return nd.array(cm[x,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 29\n",
      "13 45 14 46\n",
      "5 25\n",
      "9 41 0 21\n",
      "2 10\n",
      "0 26 0 18\n",
      "17 6\n",
      "0 22 1 33\n",
      "36 51\n",
      "35 63 20 52\n",
      "-13 -10\n",
      "0 6 0 3\n",
      "22 19\n",
      "3 35 6 38\n",
      "9 17\n",
      "1 33 0 25\n",
      "18 23\n",
      "7 39 2 34\n",
      "4 1\n",
      "0 17 0 20\n",
      "29 37\n",
      "21 53 13 45\n",
      "28 35\n",
      "19 51 12 44\n",
      "33 38\n",
      "22 54 17 49\n",
      "25 31\n",
      "15 47 9 41\n",
      "31 32\n",
      "16 48 15 47\n",
      "22 26\n",
      "10 42 6 38\n",
      "39 44\n",
      "28 60 23 55\n",
      "59 68\n",
      "52 63 43 63\n",
      "25 36\n",
      "20 52 9 41\n",
      "34 24\n",
      "8 40 18 50\n",
      "54 60\n",
      "44 63 38 63\n",
      "34 22\n",
      "6 38 18 50\n",
      "47 34\n",
      "18 50 31 63\n",
      "60 72\n",
      "56 63 44 63\n",
      "29 39\n",
      "23 55 13 45\n",
      "41 35\n",
      "19 51 25 57\n",
      "25 25\n",
      "9 41 9 41\n",
      "40 29\n",
      "13 45 24 56\n",
      "46 40\n",
      "24 56 30 62\n",
      "25 15\n",
      "0 31 9 41\n",
      "34 23\n",
      "7 39 18 50\n",
      "92 69\n",
      "53 63 63 63\n",
      "25 30\n",
      "14 46 9 41\n",
      "19 17\n",
      "1 33 3 35\n",
      "40 44\n",
      "28 60 24 56\n",
      "30 45\n",
      "29 61 14 46\n",
      "41 51\n",
      "35 63 25 57\n",
      "34 31\n",
      "15 47 18 50\n",
      "38 46\n",
      "30 62 22 54\n",
      "32 39\n",
      "23 55 16 48\n",
      "63 0\n",
      "0 16 47 63\n",
      "27 42\n",
      "26 58 11 43\n",
      "43 25\n",
      "9 41 27 59\n",
      "39 -43\n",
      "0 0 23 55\n",
      "23 17\n",
      "1 33 7 39\n",
      "46 33\n",
      "17 49 30 62\n",
      "45 39\n",
      "23 55 29 61\n",
      "42 50\n",
      "34 63 26 58\n",
      "2 27\n",
      "11 43 0 18\n",
      "18 31\n",
      "15 47 2 34\n",
      "31 27\n",
      "11 43 15 47\n",
      "24 23\n",
      "7 39 8 40\n",
      "33 53\n",
      "37 63 17 49\n",
      "18 30\n",
      "14 46 2 34\n",
      "21 -8\n",
      "0 8 5 37\n",
      "11 9\n",
      "0 25 0 27\n",
      "25 41\n",
      "25 57 9 41\n",
      "83 -21\n",
      "0 0 63 63\n",
      "32 17\n",
      "1 33 16 48\n",
      "46 39\n",
      "23 55 30 62\n",
      "27 21\n",
      "5 37 11 43\n",
      "49 59\n",
      "43 63 33 63\n",
      "45 38\n",
      "22 54 29 61\n",
      "24 41\n",
      "25 57 8 40\n",
      "49 30\n",
      "14 46 33 63\n",
      "37 36\n",
      "20 52 21 53\n",
      "30 29\n",
      "13 45 14 46\n",
      "12 34\n",
      "18 50 0 28\n",
      "42 61\n",
      "45 63 26 58\n",
      "27 34\n",
      "18 50 11 43\n",
      "42 15\n",
      "0 31 26 58\n",
      "42 43\n",
      "27 59 26 58\n",
      "41 15\n",
      "0 31 25 57\n",
      "26 39\n",
      "23 55 10 42\n",
      "53 22\n",
      "6 38 37 63\n",
      "42 9\n",
      "0 25 26 58\n",
      "50 54\n",
      "38 63 34 63\n",
      "60 18\n",
      "2 34 44 63\n",
      "71 82\n",
      "63 63 55 63\n",
      "56 33\n",
      "17 49 40 63\n",
      "46 41\n",
      "25 57 30 62\n",
      "21 15\n",
      "0 31 5 37\n",
      "32 70\n",
      "54 63 16 48\n",
      "43 56\n",
      "40 63 27 59\n",
      "19 47\n",
      "31 63 3 35\n",
      "36 29\n",
      "13 45 20 52\n",
      "39 22\n",
      "6 38 23 55\n",
      "28 36\n",
      "20 52 12 44\n",
      "33 32\n",
      "16 48 17 49\n",
      "25 40\n",
      "24 56 9 41\n",
      "29 25\n",
      "9 41 13 45\n",
      "28 38\n",
      "22 54 12 44\n",
      "69 40\n",
      "24 56 53 63\n",
      "41 51\n",
      "35 63 25 57\n",
      "39 33\n",
      "17 49 23 55\n",
      "41 43\n",
      "27 59 25 57\n",
      "21 22\n",
      "6 38 5 37\n",
      "33 38\n",
      "22 54 17 49\n",
      "27 21\n",
      "5 37 11 43\n",
      "34 24\n",
      "8 40 18 50\n",
      "22 21\n",
      "5 37 6 38\n",
      "33 58\n",
      "42 63 17 49\n",
      "40 42\n",
      "26 58 24 56\n",
      "28 29\n",
      "13 45 12 44\n",
      "33 21\n",
      "5 37 17 49\n",
      "24 30\n",
      "14 46 8 40\n",
      "44 33\n",
      "17 49 28 60\n",
      "29 37\n",
      "21 53 13 45\n",
      "28 8\n",
      "0 24 12 44\n",
      "48 33\n",
      "17 49 32 63\n",
      "40 42\n",
      "26 58 24 56\n",
      "42 54\n",
      "38 63 26 58\n",
      "52 52\n",
      "36 63 36 63\n",
      "46 29\n",
      "13 45 30 62\n",
      "32 23\n",
      "7 39 16 48\n",
      "42 37\n",
      "21 53 26 58\n",
      "23 27\n",
      "11 43 7 39\n",
      "88 83\n",
      "63 63 63 63\n",
      "41 52\n",
      "36 63 25 57\n",
      "45 46\n",
      "30 62 29 61\n",
      "64 70\n",
      "54 63 48 63\n",
      "24 15\n",
      "0 31 8 40\n",
      "38 36\n",
      "20 52 22 54\n",
      "36 -5\n",
      "0 11 20 52\n",
      "22 9\n",
      "0 25 6 38\n",
      "35 15\n",
      "0 31 19 51\n",
      "51 25\n",
      "9 41 35 63\n",
      "25 32\n",
      "16 48 9 41\n",
      "38 29\n",
      "13 45 22 54\n",
      "33 11\n",
      "0 27 17 49\n",
      "29 5\n",
      "0 21 13 45\n",
      "38 46\n",
      "30 62 22 54\n",
      "48 47\n",
      "31 63 32 63\n",
      "27 14\n",
      "0 30 11 43\n",
      "31 19\n",
      "3 35 15 47\n",
      "28 26\n",
      "10 42 12 44\n",
      "26 18\n",
      "2 34 10 42\n",
      "48 6\n",
      "0 22 32 63\n",
      "50 40\n",
      "24 56 34 63\n",
      "18 16\n",
      "0 32 2 34\n",
      "32 33\n",
      "17 49 16 48\n",
      "26 24\n",
      "8 40 10 42\n",
      "43 48\n",
      "32 63 27 59\n",
      "33 29\n",
      "13 45 17 49\n",
      "56 52\n",
      "36 63 40 63\n",
      "41 47\n",
      "31 63 25 57\n",
      "43 43\n",
      "27 59 27 59\n",
      "36 20\n",
      "4 36 20 52\n",
      "36 42\n",
      "26 58 20 52\n",
      "35 36\n",
      "20 52 19 51\n"
     ]
    }
   ],
   "source": [
    "test_images,test_labels = read_images(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_acc(result, label, index):\n",
    "    if(len(np.where(result.asnumpy()>0)[1]) ==0 or len(np.where(label.asnumpy()>0)[1]) ==0):\n",
    "        return False,False,False,False\n",
    "#     result_maxx = np.max(np.where(result.asnumpy()>0)[1])\n",
    "#     result_minx = np.min(np.where(result.asnumpy()>0)[1])\n",
    "#     result_maxy = np.max(np.where(result.asnumpy()>0)[0])\n",
    "#     result_miny = np.min(np.where(result.asnumpy()>0)[0])\n",
    "\n",
    "#     result_centerx = int((result_maxx + result_minx)/2)\n",
    "#     result_centery = int((result_maxy + result_miny)/2)\n",
    "    txt_filename1 = txt_root + '/400_junior' + \"/%03d.txt\" % index\n",
    "    txt_filename2 = txt_root + '/400_predict_average' + \"/%03d.txt\" % index\n",
    "\n",
    "    with open(txt_filename1, 'r') as f:\n",
    "        txts = f.read().split()\n",
    "    with open(txt_filename2, 'r') as f:\n",
    "        txts1 = f.read().split()\n",
    "    x = int(txts[landmark_index].split(',')[0])- int(txts1[landmark_index].split(',')[0]) + 32\n",
    "    y = int(txts[landmark_index].split(',')[1])- int(txts1[landmark_index].split(',')[1]) + 32\n",
    "    \n",
    "    result_avgx = np.average(np.where(result.asnumpy()>0)[1])\n",
    "    result_avgy = np.average(np.where(result.asnumpy()>0)[0])\n",
    "\n",
    "#     label_maxx = np.max(np.where(label.asnumpy()>0)[1])\n",
    "#     label_minx = np.min(np.where(label.asnumpy()>0)[1])\n",
    "#     label_maxy = np.max(np.where(label.asnumpy()>0)[0])\n",
    "#     label_miny = np.min(np.where(label.asnumpy()>0)[0])\n",
    "    \n",
    "#     label_centerx = int((label_maxx + label_minx)/2)\n",
    "#     label_centery = int((label_maxy + label_miny)/2)\n",
    "    \n",
    "#     lable_avgx = np.average(np.where(label.asnumpy()>0)[1])\n",
    "#     lable_avgy = np.average(np.where(label.asnumpy()>0)[0])\n",
    "    \n",
    "#     d1 = pow((result_centerx - label_centerx),2) + pow((result_centery - label_centery),2)\n",
    "#     print(result_avgx,result_avgy)\n",
    "    d2 = pow((result_avgx - x),2) + pow((result_avgy - y),2)\n",
    "#     print(\"============================\")\n",
    "#     print(np.where(result.asnumpy()>0))\n",
    "#     print(result_centerx,label_centerx)\n",
    "#     print(result_centery,label_centery)\n",
    "#     print(d1,d2)\n",
    "    return (d2 < 400, d2 < 625, d2 < 900, d2 < 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2866666666666667    0.36    0.44666666666666666    0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "n = len(test_images)\n",
    "# n = 10\n",
    "imgs = []\n",
    "acc1 = 0\n",
    "acc2 = 0\n",
    "acc3 = 0\n",
    "acc4 = 0\n",
    "\n",
    "# print(test_images[0])\n",
    "for i in range(n):\n",
    "    x = test_images[i]\n",
    "#     print(x.shape)\n",
    "#     start = time()\n",
    "    result = predict(x)\n",
    "    f1,f2,f3,f4 = evaluate_acc(result,test_labels[i],i+151)\n",
    "    acc1 += int(f1)\n",
    "    acc2 += int(f2)\n",
    "    acc3 += int(f3)\n",
    "    acc4 += int(f4)\n",
    "\n",
    "\n",
    "#     print(type(np.where(result.asnumpy()>0)[0]))\n",
    "#     print(np.where(test_labels[i].asnumpy()>0))\n",
    "    pred = label2image(predict(x))\n",
    "    imgs += [x, pred, label2image(test_labels[i])]\n",
    "print(acc1/n,\"  \", acc2/n,\"  \", acc3/n,\"  \", acc4/n)\n",
    "# utils.show_images(imgs, nrows=n, ncols=3, figsize=(6,20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_images,test_labels = read_images(18,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n = 10\n",
    "# imgs = []\n",
    "# for i in range(n):\n",
    "#     x = test_images[i]\n",
    "#     imgs += [x, label2image(test_labels[i]), label2image(test_labels[i])]\n",
    "# # \n",
    "# utils.show_images(imgs, nrows=n, ncols=3, figsize=(6,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
